This book discusses an emerging approach to
architecture in which building performance is a
guiding design principle. This architecture places
broadly defined performance above, or on a par
with, form-making; it utilizes digital technologies of
quantitative and qualitative performance-based
simulation to offer a comprehensive new approach
to the design of the built environment.

In this new information- and simulation-driven
design context, the paradigm of performance-based
design can be approached very broadly -- its
meaning spans multiple realms, from spatial, social
and cultural to purely technical (structural,
thermal, acoustical, etc.). The increasing emphasis
on building performance -- from the cultural and
social context to building physics -- is influencing
building design, its processes and practices, by
blurring the distinctions between geometry and
analysis, between appearance and performance. By
integrating the design and analysis of buildings
around digital technologies of modeling and
simulation, the architect's and engineer's roles are
increasingly being integrated into a relatively
seamless digital collaborative enterprise from the
earliest, conceptual stages of design.

The contents of this book emerged out of the
symposium on "Performative Architecture" held at
the University of Pennsylvania in October 2003.
That event brought together some of the leading
individuals from different realms -- architects,
engineers, theoreticians, technologists -- who
comprise the contributors to this book, with the aim of
providing informed views of what is meant by
performances in architecture and of architecture.

The idea for the symposium was based on
discussions between Ali Malkawi and myself about the
apparent "disconnect" between geometry and analysis
in the currently available digital tools. Our initial
scrutiny of the tools (the instruments) that are used to
digitally simulate the performance of buildings -- the
tools that are increasingly accessible to architects and
their consultants -- provoked broader questions, such
as to what extent performance actually influences
design and what performance means in architecture.

As we engaged the theme in its broader dimensions,
we discovered that little has been written about
performance in architecture. Yet this term --
performance -- has been widely used by owners,
designers, engineers, cultural theorists, etc.
Performance in architecture increasingly matters;
however, it means different things to different people.

The chapters in this book provide a diverse set of
ideas as to how building performance is relevant today
and how it might be relevant tomorrow for architectural
and engineering design practices. The projects discussed
provide snapshots of different approaches, grounded in
actual practices already taking place.

As readers will notice, the meanings of
performance in architecture are indeed multiple and
intertwined, and are irreducible to a simple, succinct
definition. Performance, however, will increasingly
underlie discussions about architecture in the future.


In avant-garde contemporary architectural design, various
digital generative and production processes are opening up
new territories for conceptual, formal and tectonic
exploration, articulating an architectural morphology
focused on the emergent and adaptive properties of form.1
In a radical departure from centuries-old traditions and
norms of architectural design, digitally-generated forms
are not designed or drawn as the conventional
understanding of these terms would have it, but they are
calculated by the chosen generative computational method.
Instead of working on a parti, the designer constructs a
generative system of formal production, controls its
behavior over time, and selects forms that emerge from its
operation. The emphasis shifts from the "making of form"
to the "finding of form," which various digitally-based
generative techniques seem to bring about intentionally.

The new, speculative design work of the digital avantgarde, enabled by time-based modeling techniques, is
provoking an interesting debate about the possibilities and
challenges of the digital generation of form (i.e. the digital
morphogenesis).2 There is an aspiration to manifest
formally the invisible dynamic processes that are shaping
the physical context of architecture (figure 14.1), which, in
turn, are driven by the socio-economic and cultural forces
within a larger context. According to Greg Lynn, "the
context of design becomes an active abstract space that
directs from within a current of forces that can be stored
as information in the shape of the form."3 Formal
complexity is often intentionally sought out, and this
morphological intentionality is what motivates the
processes of construction, operation and selection.

This dynamic, time-driven shift in conceptualization
techniques, however, should not be limited to the issues of
representation, i.e. formal appearance, only. While we now
have the means to visualize the dynamic forces that affect
architecture by introducing the dimension of time into the
processes of conceptualization, we can begin to qualify
their effects and, in the case of certain technical aspects,
begin to quantify them too. There is a range of digital
analytical tools that can help designers assess certain
performative aspects of their projects, but none of them
provide dynamic generative capabilities yet.

PERFORMANCE-BASED  DESIGN
The aesthetics of many projects of the digital avant-garde,
however, are often sidetracking the critical discourse into
the more immediate territory of formal expression and
away from more fundamental possibilities that are
opening up. Such possibilities include the emergence of
performance-based design, in which building performance
becomes a guiding design principle, considered on a par
with or above form-making.

The current interest in building performance as a
design paradigm is largely due to the emergence of
sustainability as a defining socio-economic issue and to
the recent developments in technology and cultural theory.
Within such an expansive context, building performance
can be defined very broadly, across multiple realms, from
financial, spatial, social and cultural to purely technical
(structural, thermal, acoustical, etc.). The issues of
performance (in all its multiple manifestations) are
considered not in isolation or in some kind of linear
progression but simultaneously, and are engaged early on
in the conceptual stages of the project, by relying on close
collaboration between the many parties involved in the
design of a building. In such a highly "networked" design
context, digital quantitative and qualitative performance-based simulations are used as a technological foundation
for a comprehensive new approach to the design of the
built environment.

It is important to note that performance-based design
should not be seen as simply a way of devising a set of
practical solutions to a set of largely practical problems,
i.e. it should not be reduced to some kind of neo-functionalist approach to architecture. The emphasis
shifts to the processes of form generation based on
performative strategies of design that are grounded, at
one end, in intangibilities such as cultural performance
and, at the other, in quantifiable and qualifiable
performative aspects of building design, such as structure,
acoustics or environmental design. Determining the
different performative aspects in a particular project and
reconciling often conflicting performance goals in a
creative and effective way are some of the key challenges
in performance-based design.


The Dynaform BMW Pavilion
at the IAA'01 Auto Show in
Frankfurt, Germany (2000-
01), architects Bernhard
Franken and ABB Architekten.


CALCULATING PERFORMANCE THEN
The performative design thinking, framed by a broadly
defined performance agenda and supported by a range
of digital performance analysis and simulation tools,
as outlined briefly above, was envisioned decades ago.
Back in the late 1960s and early 1970s, a group of
researchers led by Thomas Maver at ABACUS
(Architecture and Building Aids Computer Unit
Strathclyde) at the University of Strathclyde's
Department of Architecture and Building Science,
proposed that the building design be directly driven
and actively supported by a range of integrated
"performance appraisal aids" running on computer
systems.4

Digital building performance "appraisal aids" and
performance-based design were at the center of
computer-aided building design research for more than
three decades -- many of the essential concepts and
techniques were pioneered in the late 1960s and early
1970s. For example, the first use of computer graphics
for building appraisal was in 1966, the first integrated
package for building performance appraisal appeared
in 1972, the first computer-generated perspective
drawings appeared in 1973, etc.5 The 1970s resulted
in the "generation of a battery of computer aids for
providing the designer with evaluative feedback on his
design proposals," enabling architects to "obtain
highly accurate predictions of such building
performance measures as heat loss, daylight contours,
shadow projections and acoustic performance."6

One of the first digital performance analysis tools
to emerge was PACE (Package for Architectural
Computer Evaluation), developed at ABACUS and
introduced in 1970 as a "computer-aided appraisal

facility for use at strategic stages in architectural
design," which, unlike many of the efforts at the time,
aimed "not on optimization of a single parameter but
on production of a comprehensive and integrated set of
appraisal measures."7 PACE was written in FORTRAN
and run on a time-sharing system; the "conversational
interaction" was through a teletypewriter terminal. The
program measured costs, "spatial," environmental and
"activity" performance. The "spatial performance"
component measured site utilization (plot ratio) and
plan and mass compactness. Computing the
environmental performance resulted in "plant sizes
which [would] give adequate environmental
conditions," while taking into account the heat gain and
loss. The "activity performance" module measured "the
degree to which the relationships input under activity
information are satisfied by the proposed scheme."

The program would instruct the designer how to
change geometrical or constructional information, i.e.
how to modify the design concept to improve
performance and then submit the modified design for
"re-appraisal." In the end, the "repetitive man/machine
interaction" would lead to "convergence of an
`optimum' design solution." A particularly interesting
aspect of the program was its built-in capacity to
"learn:" if the designer was satisfied with the scheme,
the program would update the stored mean values used
in assessments.8

As is often the case with visionary ideas, much of
the early work in digitally-driven performance-based
design was far ahead of its time both conceptually and
technologically. But its time has now come, as
performance-based design is slowly but steadily coming
to the forefront of architectural discourse.

14.2
Finite-element analysis
(FEA) stress analyses of
the Dynaform BMW
Pavilion for the 2001
Auto Show in Frankfurt,
Germany, by Bollinger
+ Grohman Consulting
Engineers, architects
Bernhard Franken and
ABB Architekten.

14.3
The FEA analysis
of stresses for the
Swiss Re building,
London (1997-
2004), by Arup,
architect Foster
and Partners.

14.4
The CFD
analysis of wind
flows for Project
ZED in London
(1995) by Arup,
architect Future
Systems.

197
SIMULATING PERFORMANCE NOW
Today, digital quantitative and qualitative performancebased simulation represents the technological foundation
of the emerging performative architecture described
earlier. Analytical computational techniques based on
the finite-element method (FEM), in which the
geometric model is divided into small, interconnected
mesh elements, are used to accurately perform

14.5
An early
computer
rendering of the
structural system
for Kunsthaus
Graz, Austria
(2000-03),
architects Peter
Cook and Colin
Fournier
(spacelab.uk).

14.6
The acoustical
analysis of the
debating chamber
in the City Hall,
London (1998-
2002) by Arup,
architect Foster
and Partners.

14.7
Gaussian analysis,
Experience Music
Project, Seattle
(1999-2000),
architect Gehry
Partners.

structural, energy and fluid dynamics analyses for
buildings of any formal complexity. These quantitative
evaluations of specific design propositions can be
qualitatively assessed today thanks to improvements in
graphic output and visualization techniques (figures
14.2-14.6). By superposing various analytical
evaluations, design alternatives could be compared with
relative simplicity to select a solution that offers desired
performance.

Future Systems, a design firm from London, used
computational fluid dynamics (CFD) analysis in a
particularly interesting fashion in its Project ZED, the
design of a multiple-use building in London (1995; figure
14.4). The building was meant to be self-sufficient in
terms of its energy needs by incorporating photovoltaic
cells in the louvers and a giant wind turbine placed in a
huge hole in its center. The curved form of the fac,ade was
thus designed to minimize the impact of the wind at the
building's perimeter and to channel it towards the turbine
at the center. The CFD analysis was essential in improving
the aerodynamic performance of the building envelope.

The original blobby shape of Peter Cook and Colin
Fournier's competition winning entry for the Kunsthaus
Graz, Austria (figure 14.5), was altered somewhat after
the digital structural analysis by consulting engineers
Bollinger + Grohmann from Frankfurt revealed that its
structural performance could be improved with minor
adjustments in the overall form, by extracting the
isoparametric curves for the envelope definition not from
the underlying NURBS geometry but from the structural
analysis. Likewise, Foster and Partners' design for the
main chamber of the London City Hall (figure 14.6) had
to undergo several significant changes after engineers
from Arup analyzed its acoustical performance using inhouse developed acoustic wave propagation simulation
software.

In Gehry's office, Gaussian analysis is used to
determine the extent of curvature of different areas on
the surface of the building (figure 14.7). That way the
designers can quickly assess the material performance,
i.e. whether the material can be curved as intended, as
there are limits to how much a particular material with a
particular thickness can be deformed. More importantly,
the curvature analysis provides quick, visual feedback
about the overall cost of the building's "skin," as doublycurved areas (shown in red) are much more expensive to
manufacture than the single-curved sections (shown in
green and blue tones).

198

As these examples demonstrate, the feedback provided
by visualization techniques in the current building
performance simulation software can be very effective
in design development. The software, however, operates
at the systemic level in the same passive fashion as two
or three decades ago. "Computer-aided appraisal" now
and back in 1980, as described by Thomas Maver, has
consisted of four main elements: representation,
measurement, evaluation and modification:

The designer generates a design hypothesis which is
input into the computer (representation); the
computer software models the behaviour of the
hypothesized design and outputs measures of cost
and performance on a number of relevant criteria
(measurements); the designer (perhaps in
conjunction with the client body) exercises his (or
their) value judgement (evaluation) and decides on
appropriate changes to the design hypothesis
(modification).9

As noted by Maver, "if the representation and
measurement modules of the design system can be set
up and made available, the processes of evaluation and
modification take place dynamically within the design
activity as determinants of, and in response to, the
pattern of explorative search," which is a fairly
accurate description of how performance analysis
("appraisal") software is being used today.

CHALLENGES
Designing buildings that perform (i.e. "which work --
economically, socially and technically") is a central
challenge for architects, as observed by Thomas Maver
back in 1988.10 He called for the development of
"software tools for the evaluation of the technical issues
which are relevant at the conceptual stages, as opposed
to the detailed stages, of design decision-making."11

The challenges of developing such software,
however, are far from trivial. Most of the commercially
available building performance simulation software,
whether for structural, lighting, acoustical, thermal or

air-flow analysis, requires high-resolution, i.e. detailed,
modeling, which means that it is rarely used in conceptual
design development. This shortcoming, and the lack of
usable "low-resolution" tools, is further compounded by
the expected degree of the user's domain knowledge and
skills. Another frequently encountered problem is that
certain performance aspects can be analyzed in one
environment while other performative analyses must be
performed in some other software, often resulting in
substantial and redundant remodeling. Providing a certain
degree of representational integration across a range of
"low-resolution" performance simulation tools is a
necessary step for their more effective use in conceptual
design.

Assuming that analytical and representational
integration can be achieved, and that intuitive "lowresolution" performance simulation tools can be developed,
additional challenges are presented by the need for active
design space exploration. Instead of being used in a
passive, "after-the-fact" fashion, i.e. after the building
form has already been articulated, as is currently the case,
analytical computation could be used to actively shape the
buildings in a dynamic fashion, in a way similar to how
animation software is used in contemporary architecture.12
In other words, the performance assessment has to be
generative and not only evaluative. For that to happen,
however, a fundamental rethinking of how the digital
performance simulation tools are conceptualized is
required.

Ulrich Flemming and Ardeshir Mahdavi argued in
1993 for the close "coupling" of form generation and
performance evaluation for use in conceptual design.13
Mahdavi developed an "open" simulation environment
called SEMPER, with a "multidirectional" approach to
simulation-based performance evaluation.14 According to
Mahdavi, SEMPER provides comprehensive performance
modeling based on first principles, "seamless and dynamic
communication between the simulation models and an
object-oriented space-based design environment using the
structural homology of various domain representations,"
and bi-directional inference through "preference-based
performance-to-design  mapping  technology."

199

PERFORMANCE-BASED GENERATIVE DESIGN
As Kristina Shea observed, "generating new forms while
also having instantaneous feedback on their performance
from different perspectives (space usage, structural,
thermal, lighting, fabrication, etc.) would not only spark
the imagination in terms of deriving new forms, but
guide it towards forms that reflect rather than contradict
real design constraints."15 As a structural engineer, she
cites the form-finding techniques used in the design of
tensile membrane structures (pioneered by Frei Otto) as
the nearest example of performance-driven architectural
form generation, in which the form of the membrane is

14.8
Canopy design
developed using
eifForm for the
courtyard of the
Academie van
Bouwkunst in
Amsterdam (2002),
designed by Neal
Leach, Spela
Videcnik (OFIS
Architects), Jaroen
van Mechelen and
Kristina Shea.

dynamically affected by changing the forces that act on
the model. She notes that the form-finding techniques in
structural engineering are generally limited to either pure
tensile or pure compression structures, and she promotes
the need for developing digital tools that can generate
mixed-mode structural forms.16

According to Kristina Shea, a generative approach to
structural design requires a design representation of form
and structure that encodes not only (parametric) geometry
but also a design topology based on the connectivity of
primitives.17 The experimental software she developed,
called eifForm, is based on a structural shape grammar
that can generate design topology and geometry, enabling
the transformation of form while simultaneously
maintaining a meaningful structural system. Primitives
and their connectivity are added, removed and modified
with a built-in randomness in design generation, directed
by a non-deterministic, non-monotonic search algorithm
based on an optimization technique called "simulated
annealing," analogous to the "crystallization processes in
the treatment of metals."18 The software develops the
overall form of a structure dynamically, in a time-based
fashion, "by repeatedly modifying an initial design with
the aim of improving a predefined measure of
performance, which can take into account many different
factors, such as structural efficiency, economy of
materials, member uniformity and even aesthetics, while
at the same time attempting to satisfy structural
feasibility constrains." The end product is a triangulated
pattern of individually-sized structural elements and joints
(figures 14.8 and 14.9).

In a similar vein, I have proposed in a recent paper19
the development of generative tools based on performance
evaluation in which, for example, an already structured
building topology, with a generic form, could be subjected
to dynamic, metamorphic transformation resulting from
the computation of performance targets set at the outset.
Such a dynamic range of performative possibilities would
contain at its one end an unoptimized solution and at the
other an optimized condition (if it is computable), which
might not be an acceptable proposition from an aesthetic
or some other point of view. In that case, a suboptimal

14.9
eifForm:
progressive
generation of
the canopy
design.

200

form, i.e. its discovery, in qualitative cognition. Even though
the technological context of design is thoroughly externalized,
its arresting capacity remains internalized. The generative
role of the proposed digital techniques is accomplished
through the designer's simultaneous interpretation and
manipulation of a computational construct (topological
configuration subjected to particular performance
optimizations) in a complex discourse that is continuously
reconstituting itself -- a "self-reflexive" discourse in which
graphics actively shape the designer's thinking process.

CONCLUSION
In conclusion, the new "performative" approach to design
requires, at a purely instrumental level, yet-to-be-made digital
design tools that can provide dynamic processes of formation
based on specific performative aspects of design. There is
currently an abundance of digital analytical tools that can
help designers assess certain performative aspects of their
projects post-facto, i.e. after an initial design is developed, but
none of them provide dynamic generative capabilities that
could open up new territories for conceptual exploration in
architectural design. More importantly, the emergence of
performance-based generative design tools would lead to new
synergies between architecture and engineering in a
collaborative quest to produce unimaginable built forms that
are multiply performative.

solution could be selected from the in-between
performative range, one that could potentially satisfy
other non-quantifiable performative criteria.

This new kind of analytical software will preserve
the topology of the proposed schematic design but will
alter the geometry in response to optimizing a particular
performance criteria (acoustic, thermal, etc.). For
example, if there is a particular geometric configuration
comprised of polygonal surfaces, the number of faces,
edges and vertices would remain unchanged (i.e. the
topology does not change), but the shapes (i.e. the
geometry) will be adjusted (and some limits could be
imposed in certain areas). The process of change could
be animated, i.e. from the given condition to the optimal
condition, with the assumption that the designer could
find one of the in-between conditions interesting and
worth pursuing, even though it may not be the most
optimal solution (figure 14.10).

In this scenario, the designer becomes an "editor" of
the morphogenetic potentiality of the designed system,
where the choice of emergent forms is driven largely by
the project's quantifiable performance objectives and the
designer's aesthetic and plastic sensibilities. The capacity
to generate "new" designs becomes highly dependent on
the designer's perceptual and cognitive abilities, as
continuous, dynamic processes ground the emergent

204

15

BRANKO  KOLAREVIC
TOWARDS  THE
IN  ARCHITECTUREPERFORMATIVE

205

We might distinguish between two kinds of spatial
disposition, effective and affective. In the first, one
tries to insert movements, figures, stories, activities
into some larger organization that predates and
survives them; the second, by contrast, seeks to release
figures or movements from any such organization,
allowing them to go off on unexpected paths or relate
to one another in undetermined ways.

John Rajchman1

In the late 1950s, performance emerged in humanities
-- in linguistics and cultural anthropology in particular
-- and in other research fields as a fundamental
concept of wide impact. It shifted the perception of
culture as a static collection of artifacts to a web of
interactions, a dynamic network of intertwined,
multilayered processes that contest fixity of form,
structure, value or meaning. Social and cultural
phenomena were seen as being constituted, shaped and
transformed by continuous, temporal processes defined
by fluidity and mediation; thus a performative
approach to contemporary culture emerged.

As a paradigm in architecture, performance can be
understood in those terms as well; its origins can be
also traced to the social, technological and cultural
milieu of the mid-twentieth century. The utopian
designs of the architectural avant-garde of the 1960s
and early 1970s, such as Archigram's "soft cities,"
robotic metaphors and quasi-organic urban landscapes,
offered images of fantasies based on mechanics and
pop culture; they have particular resonance today, as
cultural identity and spatial practice are being
rethought through performative acts that recode, shift
and transform meanings in a true, semiotic sense.

In this spirit, performative architecture can be
described as having a capacity to respond to changing
social, cultural and technological conditions by
perpetually reformatting itself as an index, as well as a
mediator of (or an interface to) emerging cultural
patterns.2 Its spatial program is not singular, fixed or
static, but multiple, fluid and ambiguous, driven by
temporal dynamics of socio-economic, cultural and

technological shifts. In performative architecture,
culture, technology and space form a complex, active web
of connections, a network of interrelated constructs that
affect each other simultaneously and continually. In
performative architecture, space unfolds in indeterminate
ways, in contrast to the fixity of predetermined,
programmed actions, events and effects.

The description of performative architecture given
above is one of many -- its paradigmatic appeal lies
precisely in the multiplicity of meanings associated with
the performative in architecture.3 The increasing interest
in performance as a design paradigm is largely due to the
recent developments in technology and cultural theory
and the emergence of sustainability as a defining socioeconomic issue. Framed within such expansive context,
the performative architecture can indeed be defined very
broadly -- its meaning spans multiple realms, from
financial, spatial, social and cultural to purely technical
(structural, thermal, acoustical, etc.). In other words, the
performative in architecture is operative on many levels,
beyond just the aesthetic or the utilitarian.

ARCHITECTURE AS PERFORMANCE
At the urban scale, architecture operates between the
opposing poles of "smooth" urban space (by blending in)
and urban landmarks (that stand out). Contemporary
avant-garde architecture advances the latter towards
architecture as performance art, which takes the urban
setting as a stage on which it literally and actively
performs.

Some of the recent projects by Lars Spuybroek
(NOX), such as the D-Tower4 in Doetinchem, the
Netherlands (1998-2003), and Maison Folie5 in Lille,
France (2001-04), can literally be seen as architectural
performance pieces. D-Tower is a hybrid digital and
material construct (figure 15.1), which consists of a
biomorphic built structure (the tower), a website and a
questionnaire that form an interactive system of
relationships in which "the intensive (feelings, qualities)
and the extensive (space, quantities) start exchanging
roles, where human action, color, money, value, feelings
all become networked entities."6 The complex surface of

206

the 12 m tower is made of epoxy panels shaped over CNC
(computer numeric control)-milled molds (figure 15.2). The
epoxy monocoque shell is both the structure and the skin, and
thus simultaneously multi-performative from the tectonic and
building physics perspectives (figure 15.3). The tower
changes its color depending on the prevailing emotional state
of the city's residents, which is computed from responses of
the city's inhabitants to an online questionnaire7 about their
daily emotions -- hate, love, happiness and fear -- and these
are mapped into four colors (green, red, blue and yellow),
with a corresponding light illuminating the biomorphic
surfaces of the tower. The city's "state of mind" is also
accessible through the website, which also shows the
"emotional landscape" of the city's neighborhoods. So,
either by looking at the tower or the corresponding website,
one can tell the dominant emotion of the day.8 The tower also
features a capsule in which the city's inhabitants could leave
love letters, flowers, etc. To motivate participation in this
socially and culturally performative urban and architectural
experiment, a monetary prize of 10,000 euros is to be
awarded to the "address with highest emotions."

15.1
D-Tower, Doetinchem,
Netherlands (1998-
2003), architect NOX/
Lars Spuybroek.

15.2
D-Tower:
tectonic
composition.

15.3
D-Tower:
structural
analysis of
stresses.

207

In Maison Folie in Lille (figure 15.4), an old textile
factory that has been transformed into a new urban art
center,9 the added multi-purpose hall (a black box)
features an external, partially transparent skin, whose
intricate tectonic composition of metallic grilles produces
varying moire' patterns as one moves along it. Spuybroek
refers to this dynamic effect as a "static" movement, "an
animation of the vertical tectonics of the fac,ade, ...
bending vertical lines in a complex pattern that produce a
whole range of changes when walking or driving by,
enhanced by the position of the sun."10 There is also the
literal movement of changing lights placed behind the
metallic grille of the fac,ade, adding another layer of
intricacy to the building's urban performance.

Dynamic display of light, i.e. changing light patterns,
is a primary performative dimension in Peter Cook and
Colin Fournier's Kunsthaus Graz, Austria (1999-2003;
figure 15.5). BIX, the light and media installation designed
by realities:united from Berlin, is inserted behind the
acrylic glass layer to create a "communicative membrane"
-- a low-resolution computer-controlled skin, a "media
fac,ade" that, through the display of signs, announcements
and images, hints at the activities within the building
(figure 15.6). The performative aspects of the building are
all geared towards an "urban communication strategy."

The BIX light installation blurs the boundaries
between the architecture and the performance medium; in
the Kunsthaus Graz "the medium is the message."11
Extending McLuhan's ideas to performative architecture,12
one could argue that mediated, animated architectural
skins have the potential to change how we relate to the
built environment and, reciprocally, how the built
environment relates to us, as manifested in Mark
Goulthorpe's Aegis Hyposurface project, described below.

Movement and performance
It is often the movement of people around and through a
building that gives architecture its performative capacity,
as Maison Folie demonstrates. It is the experience of
architecture's spatial presence and materiality -- the
engagement of the eye and the body -- that makes
architecture  performative.

15.4
Maison Folie,
Lille, France
(2001-04),
architect NOX/
Lars Spuybroek.

15.5
Kunsthaus Graz,
Austria (1999-
2003), architects
Peter Cook and
Colin Fournier
(spacelab.uk).

15.6
BIX, the
"communicative
membrane" for
Kunsthaus Graz,
designers
realities:united.

208

In some recent projects, such as the Millennium Bridge in
Gateshead, UK (1997-2001; figures 15.7 and 15.8),
designed by Wilkinson Eyre Architects, and the
Milwaukee Art Museum (1994-2001; figures 15.9 and
15.10), designed by Santiago Calatrava, the performative
is in the kinetic effects of architecture -- it is not the
subject that moves but the object itself, creating an
architecture of spectacle, an architecture of performance.

The Millennium Bridge in Gateshead -- the "blinking
eye" bridge, as it is popularly called -- is the world's first
rotating bridge; the entire bridge rotates around pivots on
both sides of the river so that its tilt creates sufficient
clearance for the ships to pass underneath (figure 15.9).
The bridge's elegant arches appear to trap movement
even when static; their dynamic metamorphosis has been
described as resembling the slow opening of a giant eyelid
-- hence the "blinking eye" moniker.

 For the museum building in Milwaukee, Santiago
Calatrava designed a giant, movable wing-like sunscreen,
a brise soleil, over a glass-enclosed reception hall. Made
from fins ranging from 26 to 105 feet in length, the
operable brise soleil is raised and lowered to control the
amount of light (and heat) that enters into the reception
area (figure 15.10). Calatrava clearly designed the
operable brise soleil as an event, an urban performance
on Milwaukee's waterfront. The performative, however, is
not limited to the kinetics of the sunscreen; there are
many "performances in geometry and engineering"13 in

15.7
The Millennium
Bridge in Gateshead,
UK (1997-2001),
architects Wilkinson
Eyre Architects,
engineers Gifford
and Partners.

15.8
The Millennium
Bridge: the bridge's
arches in the tilted
position.

15.9
The Milwaukee
Art Museum, USA
(1994-2001),
architect and
engineer Santiago
Calatrava.

15.10
The Milwaukee
Art Museum: the
kinetic operation
of the wing-like
brise soleil.

209

this building, as is the case with almost all of
Calatrava's projects.

In addition to kinetic effects, a building's skin can
also dynamically alter its shape in response to various
environmental influences, as the Aegis Hyposurface
project by Mark Goulthorpe shows. Developed initially
as a competition entry for an interactive art piece to
be exhibited in the Birmingham Hippodrome Theatre
foyer, the Aegis Hyposurface is a digitally controlled,
pneumatically driven, deformable rubber membrane
covered with metal shingles (figure 15.11) that can
change its shape in response to electronic stimuli
resulting from movement and changes in sound and
light levels in its environment, or through
parametrically-generated patterns. The dynamic
performance of the building's skin can be either preprogrammed (determined) or in response to
environmental changes (indeterminate, interactive).

The Bilbao effect
In these and previously discussed projects, architecture's
urban performances aim beyond the spectacle of the kinetic
structures, dynamic skins and the changing light patterns.
From the stakeholders' perspective (owners, municipal and
regional governments, etc.), the intended performance of those
buildings is primarily socio-economic; as urban landmarks,
those buildings are meant to energize the urban contexts in
which they are situated. By attracting the attention of local
city dwellers and global cultural tourists, they are seen as the
sparks of urban and economic renewal. The performances (and
oftentimes forms) of these buildings become highly politicized.

This political, socio-economic and cultural performative
potential of architecture is being rediscovered due, in large
part, to what is nowadays called the "Bilbao effect," after the
socio-economic and cultural transformation of a sleepy
provincial town in northeastern Spain into a cosmopolitan
cultural magnet as a result of a bold architectural and cultural
strategy -- the synergy of the global cultural brand of the
Guggenheim Museum and the exuberance and expressiveness
of Frank Gehry's architecture.14 Not surprisingly, by reaching
out for out-of-the-ordinary architectural tactics, cities
increasingly expect miracles -- hence, the curvaceous, light
animated forms of Kunsthaus Graz, the "blinking eye" bridge
in Gateshead, and the wing-like museum in Milwaukee.

THE AESTHETICS AND ETHICS
OF THE PERFORMATIVE
Admittedly, there is a considerable degree of novelty in
complex, curvilinear forms (in spite of numerous precedents)
pursued with fervor by the contemporary architectural avantgarde.
The strong visual and formal juxtapositions created
between "blobs" and "boxes" in traditional urban contexts, as
is often the case, add to their "iconic" status and their
perception of being exceptional and marvelous. The expressive
form of the Kunsthaus Graz (figure 15.5), for example, is not
accidental -- its performative intent is aimed at the socioeconomic:
by attracting people to the area, this "Friendly
Alien," as the building is curiously named by its architects,
with its strange, mediated skin, will act as a development
catalyst (aiming for the "Bilbao effect").

15.11
Aegis
Hyposurface,
architect Mark
Goulthorpe/
dECOi.

210

Appearance  and performance
Interestingly, it is the surface -- the building's skin --
and its complex morphology and tectonics, and not
necessarily the structure, that preoccupies the work of
the contemporary (digital) avant-garde in its
exploration of new formal territories enabled by the
latest digital modeling software.15 On the other hand,
Santiago Calatrava appears to reject the skin in many
of his projects and instead seeks to harness the
expressive powers of exposed structure for its
performative potential, both literally, in the engineering
sense, and morphologically, for the beauty of forcedriven formal articulation. Another strategy is to avoid
the binary choices of skin or structure and to reunify
the two by embedding or subsuming the structure into
the skin, as in semi-monocoque and monocoque
structures. The principal idea is to conflate the
structure and the skin into one element.

This search for performance in geometry and
engineering, in turn, prompted a search for different
tectonics and "new" materials, such as hightemperature foams, rubbers, plastics and composites,
which were, until recently, rarely used in the building
industry.16 For example, the functionally gradient
polymer composite materials offer a promise of
enclosures in which material variables can be optimized
for local performance criteria, opening up entirely new
material and tectonic possibilities in architecture. For
example, transparency can be modulated in a single
surface, and structural performance can be modulated
by varying the quantity and pattern of reinforcement
fibers, etc.17

From a historic perspective, balancing
performances in geometry and material is a
continuously present theme in architecture. Geometry
was often imposed onto the material, as manifested by
various proportioning and other ordering systems. A
different approach was to let the geometry emerge from
the material and its capacity to deal with compression
and tension (i.e. the material's structural performance).
Gilles Deleuze and Felix Guattari illustrate these two
different approaches with a brief reference to

Romanesque and Gothic architecture, where the latter
represents a qualitative shift from the former, from the
"static relation, form-matter" (Romanesque) to a "dynamic
relation, material-forces" (Gothic).18 As Deleuze and
Guattari note, "it is the cutting of the stone that turns it
into material capable of holding and coordinating forces of
thrust, and of constructing higher and longer vaults."19 The
forms "are `generated' as `forces of thrust' (pousse'es) by
the material, in a qualitative calculus of the optimum."
Such "Gothic" computation of form through a material was
a method, most famously, behind Antonio Gaudi''s work (his
inverted chain-link models) and projects by Frei Otto (the
use of soap bubbles, for example). In a contemporary
architectural scene, Lars Spuybroek's "analog computing"
of form, accomplished through the use of threads dipped
into liquids, is a direct antecedent of such a performative,
materially-driven line of design thinking.20 For many
designers in the contemporary architectural avant-garde,
such as Mark Goulthorpe, Lars Spuybroek, Bernhard
Franken and others, the fluid synergies of form and
material, appearance and performance, architecture and
engineering, are intrinsically embedded into the conceptual
origins of their work.

Environmental  performance
Addressing the building's appearance ("how it looks") and
its performance ("what it does") increasingly requires
creating environmentally attuned buildings, whose physical
forms are shaped by environmental performances in respect
to light, heat, energy, movement or sound. There is
currently an interesting gap in the aesthetics (and ethics)
between form-oriented or cultural performance-oriented
designers (Frank Gehry, Greg Lynn, etc.) and those whose
work aims at environmental performance (Thomas Herzog,
Glenn Murcutt, etc.). On the other hand, there is another
group of designers -- the ones whose work is neither too
formalist or environmentalist (Foster, Grimshaw, Piano,
Sauerbruch and Hutton, Jourda and Perraudin, etc.). The
design strategies in the projects of the latter group vary
considerably as they respond to different cultural and
environmental contexts. In many of their projects, formal
and environmental performative agendas were successfully

211

pursued in parallel. In the Swiss Re project in London
(1997-2004) by Foster and Partners (figure 15.12), the
design aims at maximizing the daylight and natural
ventilation in order to substantially reduce (by half) the
amount of energy the building needs for its operation. The
spiraling form of the atria at the perimeter, which runs the
entire height of the building, is designed to generate pressure
differentials that greatly assist the natural flow of air. The
aerodynamic, curvilinear form, besides affording a
commanding, iconic presence, enables wind to flow smoothly
around this high-rise building, minimizing wind loads on the
structure and cladding, and enabling the use of a more
efficient structure. In addition, the wind is not deflected to
the ground, as is common with rectilinear buildings, helping
to maintain pedestrian comfort at the base of the building.

It is interesting to note that many of the designers
mentioned earlier -- notably Norman Foster and Nicholas
Grimshaw, once labeled High-Tech and renamed Eco-Tech by
Catherine Slessor21 -- have explicitly stated their intentions
to improve the environmental performance of their often
highly visible buildings (figure 15.12). While one could
question the methodological consistency in their projects and
whether certain performative aspects, such as energy
efficiency, were indeed maximized, these architects did
manage to consistently push the technological envelope of
environmental performance in their buildings.

An interesting example of a recent project that seems to
capture the broad agenda of performative architecture, from
cultural to environmental performance, is Renzo Piano's
Tjibaou Cultural Center for the Kanak population of New
Caledonia (1991-98; figure 15.13). The "cases" that

15.12
The Swiss Re
building in London
(1997-2004),
architect Foster
and Partners,
engineer Arup.

15.13
Section drawing of
the Tjibaou Cultural
Center in Noumea,
New Caledonia
(1991-98),
architect Renzo
Piano, engineer
Arup.

15.15
The solar
diagram for
the City Hall
building.

15.14
The City Hall in
London (1998-
2002), architect
Foster and Partners,
engineer Arup.

212

dominate the design, and that formally reference (but
do not imitate) Kanaks' huts with their cone-like
shapes, were conceived with a particular cultural
performance in mind. The cones of the "cases" were
truncated for a more efficient environmental
performance. The natural air flow within the building
is then further enhanced using a system of computercontrolled louvers on the inner skin in "cases," which
was designed and developed through wind-tunnel
testing and computer simulations by engineers at Arup
and the Centre Scientifique et Technique du Batiment
in France.

The performative design strategies can vary
considerably as they respond to different contexts.
Peter Cook and Colin Fournier's Kunsthaus Graz
(figure 15.5), which was discussed previously, features
an expressive, biomorphic blobby form, and an acrylic
glass "skin" whose primary function is to be a
"communicative membrane" -- a low-resolution
computer-controlled skin, a "media fac,ade."
Interestingly enough, there is not a hint of
environmental performance in the Kunsthaus Graz
project, as if to suggest that the formal and
environmental agendas are often incompatible --
which cannot be farther from the truth. Foster and
Partners' City Hall in London (figure 15.14; 1998-
2002), imbues an iconic, biomorphic form with a logic
of environmental performance that calls for such a
form in the first place. (The origin of the project was
purely formal -- it attained its environmental logic
later in the development.) The "pebble-like" form of
the building in the end resulted from optimization of
its energy performance by minimizing the surface area
exposed to direct sunlight. The building's form is a
deformed sphere, which has a 25% smaller surface

area than a cube of identical volume, resulting in reduced
solar heat gain and heat loss through the building's skin
(figure 15.15).

Foster's performative approach to the design of the
City Hall building, for example, could imply a significant
shift in how "blobby" forms are perceived. The sinuous,
highly curvilinear forms could become not only an
expression of new aesthetics, or a particular cultural and
socio-economic moment born out of the digital revolution,
but also an optimal formal expression for the new
ecological consciousness that calls for sustainable building.

CONCLUSIONS
Performative architecture is not a way of devising a set of
practical solutions to a set of largely practical problems. It
is a "meta-narrative" with universal aims that are
dependent on particular performance-related aspects of
each project. Determining the different performative
aspects in a particular project and reconciling often
conflicting performance goals in a creative and effective
way are some of the key challenges in this approach to
architecture.

In performative architecture, the emphasis shifts from
building's appearances to processes of formation grounded
in imagined performances, indeterminate patterns and
dynamics of use, and poetics of spatial and temporal
change. The role of architects and engineers is less to
predict, pre-program or represent the building's
performances than it is to instigate, embed, diversify and
multiply their effects in material and in time.

The development of more performative techniques of
design is essential to this task. It necessitates a shift from
scenographic appearances to pragmatist imagination of how
buildings work, what they do, and what actions, events and
effects they might engender in time.

PREFACE
This book addresses contemporary architectural practice in which digital technologies are radically changing how the buildings are conceived, designed, and produced. It discusses these digitally-driven changes, their origins, and their effects, by grounding them in actual practices already taking place, while simultaneously speculating about their wider impli- cations for the future. In that sense, the book is as much about the present (in which the digital is in the foreground) as it is about the future (in which the digital will be in the background).
The basic argument is that the digital age is forging a very different kind of architecture and, at the same time, providing unprecedented opportunities for the significant redefini- tion of the architect’s role in the production of buildings. Digital technologies are enabling a direct correlation between what can be designed and what can be built, thus bringing to the forefront the issue of the significance of information, i.e. the issues of production, com- munication, application, and control of information in the building industry. By integrating design, analysis, manufacture, and the assembly of buildings around digital technologies, architects, engineers and builders have an opportunity to fundamentally redefine the rela- tionships between conception and production. The currently separate professional realms of architecture, engineering, and construction can be integrated into a relatively seamless digital collaborative enterprise, in which architects could play a central role as information master builders, the twenty-first century version of the architects’ medieval predecessors.
One of the most profound aspects of contemporary architecture is not the rediscov- ery of complex curving forms, but the newfound ability to generate construction informa- tion directly from design information through the new processes and techniques of digital design and production. The projects discussed in the book offer snapshots of emerging ideas and examples of cutting-edge practices. They should be seen as bellwethers of the current digital evolution in architecture and as harbingers of its post-digital future.
The contents of this book emerged out of the symposium on “Designing and manu- facturing architecture in the digital age,” held at the University of Pennsylvania in March 2002. That event brought together some of the leading individuals from very different realms, with the aim of providing informed views of what is seen as a critical juncture in architecture’s evolving relationship to its wider cultural and technological context. The contributors to this book offer a diverse set of ideas as to what is relevant today and what will be relevant tomorrow for emerging architectural practices of the digital age.

2 Architecture in the Digital Age
Having abandoned the discourse of style, the architecture of modern times is characterized by its capacity to take advantage of the specific achievements of that same modernity: the innovations offered it by present-day science and technology. The relationship between new technology and new architecture even comprises a fundamental datum of what are referred to as avant-garde architectures, so fundamental as to constitute a dominant albeit diffuse motif in the figuration of new architectures.
—Ignasi de Sola Morales1
Joseph Paxton’s Crystal Palace (figure 1.1) was a bold building for its time, embodying the technological spirit of the Industrial Age and heralding a future of steel and glass buildings. Gustave Eiffel’s Tower in Paris manifested the soaring heights that new buildings could reach. It then took another 100 years for the glass and steel buildings to become ubiquitous worldwide, with gleaming skyscrapers part of every metropolis’ skyline.
The first Crystal Palaces and Eiffel Towers of the new Information Age have just been built over the past few years. Frank Gehry’s Guggenheim Museum in Bilbao (figure 1.3) is probably the best known example that captures the zeitgeist of the digital information revolution, whose consequences for the building industry are likely to be on a scale simi- lar to those of the industrial revolution: the Information Age, just like the Industrial Age before, is challenging not only how we design buildings, but also how we manufacture and construct them.
Digital technologies are changing architectural practices in ways that few were able to anticipate just a decade ago. In the conceptual realm, computational, digital architectures of topological, non-Euclidean geometric space, kinetic and dynamic systems, and genetic algorithms, are supplanting technological architectures. Digitally-driven design processes, characterized by dynamic, open-ended and unpredictable but consistent transformations of three-dimensional structures, are giving rise to new architectonic possibilities. The generative and creative potential of digital media, together with manufacturing advances already attained in automotive, aerospace and shipbuilding industries, is opening up new dimensions in architectural design. The implications are vast, as “architecture is recasting itself, becoming in part an experimental-investigation of topological geometries, partly a computational orchestration of robotic material production and partly a generative, kinematic sculpting of space,” as observed by Peter Zellner in Hybrid Space.2
It is only within the last few years that the advances in computer-aided design (CAD) and computer-aided manufacturing (CAM) technologies have started to have an impact on building design and construction practices. They opened up new opportunities by allowing production and construction of very complex forms that were, until recently, very difficult and expensive to design, produce and assemble using traditional construction technologies. A new digital continuum, a direct link from design through to construction, is established through digital technologies. The consequences will be profound, as new digitally-driven processes of design, fabrication and construction are increasingly challenging the historic relationship between architecture and its means of production.
New digital architectures are emerging from the digital revolution, architectures that have found their expression in highly complex, curvilinear forms that will gradually enter

Introduction 3
the mainstream of architectural practice in the coming years. The plural (architectures) is intentional, to imply the multiplicity of approaches—in fact, no monolithic movement exists among the digital avant-garde in architecture. What unites digital architects, designers and thinkers is not a desire to “blobify” all and everything, but the use of digital tech- nology as an enabling apparatus that directly integrates conception and production in ways that are unprecedented since the medieval times of master builders.
FROM LEIBNIZ TO DELEUZE
Contemporary approaches to architectural design are digitally enabled and digitally driven, but are also influenced and informed by the writings of theorists and philosophers, rang- ing from the German philosopher, mathematician and logician Gottfried Wilhelm Leibniz (1646–1716) to Gilles Deleuze (1925–1995), one of the most influential French thinkers of the twentieth century. It was Deleuze who demonstrated that there are a thousand “plateaus” (mille plateaux),3 a multiplicity of positions from which different provisional constructions can be created, in essentially a non-linear manner, meaning that the reality and events are not organized along continuous threads, in orderly succession. Such positions were eagerly adopted by a number of contemporary avant-garde architects to challenge the pervasive linear causality of design thinking.
In his essay on “Architectural Curvilinearity,”4 published in 1993, Greg Lynn offers examples of new approaches to design that move away from the deconstructivism’s “logic of conflict and contradiction” to develop a “more fluid logic of connectivity.” This new fluidity of connectivity is manifested through “folding,” a design strategy that departs from Euclidean geometry of discrete volumes represented in Cartesian space, and employs topological conception of form and the “rubber-sheet” geometry of continuous curves and surfaces as its ultimate expression.
Folding is one of the many terms and concepts, such as affiliation, smooth and striated space, pliancy, and multiplicity, appropriated from Deleuze’s work The Fold.5 Deleuze’s writing, aimed at describing baroque aesthetic and thought, reintroduced fold as an ambiguous spatial construct, as a figure and non-figure, an organization and non-organization, which, as a formal metaphor, has led to smooth surfaces and transitional spaces between the interior and the exterior, the building and its site. The fold, or le pli, as defined by Deleuze, posits a post-structuralist notion of space “made up of platforms, fissures, folds, infills, surfaces and depths that completely dislocate our spatial experience.” The effect of folding is a new distinctive architecture of formlessness that questions existing notions of built space, its aesthetics, and utility.
FROM BAROQUE TO GEHRY
Digitally-generated forms evolve in complex ways and their freeform surfaces curve complexly as well. As exceptions to the norm—as formal transgressions challenging the omnipresent, fundamentally rectilinear conventions—these new forms raise profound and necessary questions of an aesthetic, psychological and social nature.

4 Architecture in the Digital Age
The contemporary digital architectures appear to reject any notion of urban and structural typology, continuity and morphology, and historic style and perspectival framework—they represent an ideological, conceptual and formal break much like Walter Gropius’s Bauhaus in Dessau, Germany. They seem to prefigure an entirely new way of architectural thinking, one that ignores conventions of style or aesthetics altogether in favor of continuous experimentation based on digital generation and transformation of forms that respond to complex contextual or functional influences, both static and dynamic. The new digital architectures might be non-typological, discontinuous, amorphous, non-perspectival, ahistoric... But they are not without a precedent.
Since Baroque, architects have been trying to go beyond the Cartesian grid and the established norms of beauty and proportion in architecture. The parallels between contemporary and Baroque thought are indeed multiple, as contemporary reading of Deleuze’s Fold shows, leading to labels such as “Neo-Baroque” being applied to new architectures.
The biomorphic forms are, of course, not new, from the excesses of Baroque to organic design vocabularies of the early- and mid-twentieth century. At a purely formal level, the precedents abound. Rafael Moneo speaks of “forgotten geometries lost to us because of the difficulties of their representation.”6 The forms of Gehry’s recent projects could be traced to the Expressionism of the 1920s; one could argue that there are ample precedents for Greg Lynn’s “blobs” in Surrealism. Earlier precedents could be found in the organic, biomorphic forms of Art Nouveau or, more specifically, in the sinuous curvilinear lines of Hector Guimard’s Metro Stations in Paris. And then there is Gaudi’s oeuvre of highly sculptural buildings with complex, organic geometric forms rigorously engineered through his own invented method of modeling catenary curves by suspending linked chains.
1.4 Einsteinturm (1921), Potsdam, Germany, architect Erich Mendelsohn.
There is a range of expressive precedents from the early 1920s onwards, from Erich Mendelsohn’s Einsteinturm in Potsdam, Germany (1921, figure 1.4), to Le Corbusier’s Chapel at Ronchamp (1955, figure 1.5) and Eero Saarinen’s TWA Terminal in New York (1962, figure 1.6). It is worth remembering that it was Le Corbusier’s “free plan” and “free façade” that allowed for elements of variable curvature to emerge in the modernist projects of the mid-twentieth century. Eero Saarinen attributed the reemergence of the plastic form to the advances in building technology, while acknowledging that “it is the aesthetic reasons which are [the] driving forces behind its use.”7 Alvar Aalto broke with the pristine

Introduction 5
geometries of the International Style fairly early, applying sinuous curves to his designs from furniture and glassware to buildings. His Finnish Pavilion at the 1939 World’s Fair in New York (figure 1.7), one of his best known projects, featured dramatic undulating curves in the interior of a modest, rectilinear shell.
 1.5 Chapel at Ronchamp (1955), architect Le Corbusier.
It is interesting to note that Saarinen is rather cautious in his use of plastic form, implying that it has a rather limited applicability, and warning that the “plastic form for its own sake, even when very virile, does not seem to come off.”8 Saarinen’s cautious approach to plastic form is exemplary of the apparent ambivalence of the modernists towards the curvilinear, an attitude that is still widely present. While it enabled them to break the monotony of the orthogonal and the linear, it also heralded the emergence of a new unknown geometry, about which they were still not sure, as noted by Bernard Cache;9 the modernists “knew
 1.6. TWA Terminal (1962), New York, architect Eero Saarinen.
that they had, above all, to avoid two opposite pitfalls: a dissolution into the indefinite and a return to the representation of natural form,”10 the former manifested in “the loss of form,” and the latter in “the organicist maze into which art nouveau had fallen.”11
The utopian designs of the architectural avant-garde of the 1960s and early 1970s brought a certain state of formlessness, which, in strange ways, resembles the contemporary condition, as observed by Peter Zellner in 2001.12 It was Reyner Banham’s seminal book on Theory and Design in the First Machine Age13 that provided a significant

6 Architecture in the Digital Age
ideological shift which led to the emergence of various groups and movements, such as Archigram, Metabolism, Superstudio, etc. Archigram’s “soft cities,” robotic metaphors and quasi-organic urban landscapes were images of fantasies based on mechanics and pop culture. Expanding on Buckminster Fuller’s work, pop designers were creating “blobby” shapes throughout the 1960s and 1970s; “formable” materials, such as plastics, and con- crete to a lesser extent, inspired a free and often unrestrained treatment of form. More importantly, the works of these architects, designers and thinkers offered a new interpreta- tion of technology’s place in culture and practice, transgressing the norms of beauty and function. Archigram, for example, explored in projects, such as Plug-in City, Living Pod and Instant City, the continuity of change and choice afforded by new technologies, going beyond the superficial appearance of novel forms.
As was the case in the past, the contemporary digital architectures find their legitimiza- tion in their exploitation of the latest technological advances, new digital means of concep- tion and production, and the corresponding aesthetic of complex, curvilinear surfaces. As a manifestation of new information-driven processes that are transforming cultures, societies and economies on a global scale, they are seen as a logical and inevitable product of the digital zeitgeist.
1.7. Finnish Pavilion at the 1939 World’s Fair in New York, architect Alvar Aalto. SMOOTH ARCHITECTURES
The use of digital media by avant-garde practices is profoundly challenging the traditional processes of design and construction, but for many architects, trained in the certainties of the Euclidean geometry, the emergence of curvilinear forms poses considerable difficul- ties. In the absence of an appropriate aesthetic theory, the “hypersurface” forms (a term coined by Stephen Perrella14) often seem to be utterly esoteric and spatially difficult to comprehend, and are often dismissed as just another architectural “fad.”
What is often overlooked is that these new “smooth” architectures are tied intrinsically to a broader cultural and design discourse. Rounded contours have been omnipresent in our lives for a good part of the past decade, from toothbrushes, toasters, and computers to cars and planes (figures 1.8–1.10); somehow, perhaps in the absence of a convincing

Introduction 7
framework, the curves were widely ignored by the architectural culture until a few years ago. This formal ignorance of wider design trends also stems from yet another ignorance—the technological one—of three-dimensional digital modeling software that made the smooth curves easily attainable by industrial designers, who used them widely on everything from consumer products to airplanes. Historically, the building industry was among the last to change and adopt new technologies; CATIA (Computer Aided Three-dimensional Interac- tive Application) had been in use for 20 years before it was discovered by Gehry’s office (and is currently used by very few design offices).
Why this sudden interest and fascination with “blobby” forms? Three-dimensional digital modeling software based on NURBS (Non-Uniform Rational B-Splines), i.e. para- metric curves and surfaces, has opened a universe of complex forms that were, until the appearance of CAD/CAM technologies, very difficult to conceive, develop and represent, let alone manufacture. A new formal universe in turn prompted a search for new tectonics that would make the new undulating, sinuous skins buildable (within reasonable budgets).
1.8. Gillette Venus razor.
1.9. Apple PowerMac G4.
Inspired by the writings of thinkers ranging from Leibniz to Deleuze, as discussed earlier, some architects are exploring the spatial realms of non-Euclidean geometries, and some are basing their spatial investigations on topology, a branch of mathematics concerned with the properties of objects that are preserved through deformations. Thus, topological forms, such as torus (figure 1.11), the more complex Möbius strip (figure 1.12) and the Klein bottle (figure 1.13), have entered the architectural discourse; in some instances,

8 Architecture in the Digital Age
projects are even directly named after their topological origins, such as the Möbius House (1995, figure 1.14) by UN Studio (Ben Van Berkel and Caroline Bos) and the Torus House (2001, figure 1.15) by Preston Scott Cohen.
The appeal of the topological geometries is in part aesthetic, in part technological, and in part ideological. Topology is ultimately about relations, interconnections within a given spatial context, and not about specific forms—a single topological construct is manifest- able through multiple forms (and those forms need not be curvilinear). Topology is, in other words, less about spatial distinctions and more about spatial relations. Because topo- logical structures are often represented by mathematicians as curvilinear forms, one might think that topology is synonymous with curved surfaces, a fundamental misunderstanding which is now more or less widely adopted. Thus, in (uninformed) architectural discourse, “topological” often means “curved” and vice versa.
What should make the topology particularly appealing are not the new forms but, para- doxically, the shift of emphasis from the form to the structure(s) of relations, intercon- nections that exist internally and externally within an architectural project. Whether an architectural topological structure is given a curvilinear (“blobby”) ora rectilinear (“boxy”) form should be a resultof particular performative circumstances surrounding the project, whether they are morphological, cultural, tectonic, material, economic, and/or environ- mental.
1.10. Detail of BMW Z3 Roadster.
1.11. Torus.
Admittedly, there is a considerable degree of novelty in complex, curvilinear forms (in spite of numerous precedents) and the new digital means of creating and physically pro- ducing and constructing them. The strong visual and formal juxtapositions created between

Introduction 9 “blobs” and “boxes” intraditional urban contexts, as is often the case, add to their “iconic”
status, and their perception of being exceptional and marvelous.
1.12. Möbius strip.
The “boxes” and “blobs,” however, should not be seen as architectural opposites, but rather as instances on a sliding scale of formal complexity, that could even coexist within the same building, as was often the case in the notable modernist projects of the twentieth century and in some recent projects of the digital avant-garde. It is important to note that dissimilar forms—“blobs” and “boxes”—are not necessarily oppositional and that formal differences are not that essential (this does not mean that all geometries are alike). In the future, as buildings become more “intelligent,” it will be the information the surface trans- mits to and from the surrounding environment—and not its form—that will matter more.
1.13. Klein bottle.
DIGITAL CONTINUUM
The use of digital modeling (three-dimensional) and animation (four-dimensional) soft- ware has opened new territories of formal exploration in architecture, in which digitally-
   1.14. Conceptual diagram of the Möbius House (1995), Het Gooi, the Netherlands, archi- tects UN Studio / Ben Van Berkel and Caroline Bos.

10 Architecture in the Digital Age
generated forms are not designed in conventional ways. New shapes and forms are created by generative processes based on concepts such as topological space, isomorphic surfaces, dynamic systems, keyshape animation, parametric design and genetic algorithms- dis- cussed in more detail in the following chapter.
The changes are not purely formal. As noted earlier, by using digital technologies it is now possible to generate complex forms in novel ways and also to construct them within reasonable budgets. In other words, the processes of describing and constructing a design can be now more direct and more complex because the information can be extracted, exchanged, and utilized with far greater facility and speed; in short, with the use of digital technologies, the design information is the construction information.
This process-based change is far more significant than the formal change. It is the dig- itally-based convergence of representation and production processes that represents the most important opportunity for a profound transformation of the profession and, by exten- sion, of the entire building industry. Much of the material world today, from the simplest consumer products to the most sophisticated airplanes, is created and produced using a process in which design, analysis, representation, fabrication and assembly are becom- ing a relatively seamless collaborative process that is solely dependent on digital tech- nologies—a digital continuum from design to production. There is (the usual) one glaring exception—the building industry, which is bound to change as well, albeit very slowly, but change nevertheless.
It is interesting to note that it is the complexity of “blobby” forms that is actually draw- ing architects, out of sheer necessity, back into being closely involved with the making of buildings, thus giving them, perhaps surprisingly, more control of the building process. This position of greater control over the construction stems from the digitally-produced design information becoming construction information through the processes of data extraction and exchange.
1.15. Torus House (2001), Old Chatham, New York, architect Preston Scott Cohen.
Thus, when applied to architecture, the use of digital technologies raises not only the ques- tions of ideology, form or tectonics, but also the questions of the significance of informa- tion, and, more importantly, who controls it.

1.16. Walt Disney Concert Hall (2003), Los Angeles, architect Frank Gehry: four-dimen- sional model of the concert hall volume.
The ultimate goal becomes to construct a four-dimensional model encoded with all quali- tative and quantitative dimensional information necessary for design, analysis, fabrication and construction, plus time-based information necessary for assembly sequencing. The result is a single, cohesive, complete model that contains all the information necessary for designing and producing a building (figure 1.16). This single source of information would enable the architects to become the coordinators (master builders) of information among various professions and trades involved in the production of buildings. By digitally produc- ing, communicating and controlling the information exchanged between numerous parties in the building process, architects have an opportunity to place themselves in a central, key role in the construction of buildings and perhaps even regain the absolute powers of the medieval master builders. Whether they want to do that is a complex issue, as there are numerous social, legal and technical barriers to the complete restructuring of long-ago established relationships among the various building professions and trades.
1.18. Basilica, Piazza dei Signori (1617), Vicenza, Italy, architect Andrea Palladio.
The main technological issue is how to develop an information model for the building industry that facilitates all phases of building design and construction, and that can synthe- size information produced and exchanged between various parties. This was a long-stand- ing and yet unattained goal of the computer-aided design research community.
Introduction 11

12 Architecture in the Digital Age
FROM SHIPS TO BUILDINGS
The processes developed by the shipbuilding industry over the past two decades to coordi- nate and connect design and construction are an example of the ways in which various par- ties from the building industry—architects, engineers, fabricators and contractors— could potentially integrate their services around the digital technologies of design, analysis, fab- rication and assembly.
1.17. The Winston Churchill Aegis-class destroyer being built in the shipyard.
Ships, just like buildings, are objects of considerable technical complexity (figure 1.17). Just in terms of scale and use, there are sufficient similarities that warrant comparison (there are, of course, significant differences); it is precisely the similarities that offer opportunities for technology transfers. Both ships and buildings are large objects, with similarly complex service systems and interconnected spaces inhabited by people (in the case of passenger ships) and serving specific functions. Both have to respond to similar environmental influ- ences and functional requirements. Both represent significant undertakings that require substantial financial and material resources. Both rely on shinlar principles, methods and processes of design, analysis and production.
Differences do exist, but do not negate the notion of similarity. Designing and build- ing ships is, in fact, more complex. Structurally, ships have to resist not only gravity and wind loads, but also complex external hydrodynamic pressures. There are then additional stresses caused by propulsion systems and the motion of heavy loading equipment with which many transport ships are outfitted. Service systems in ships are more numerous, more complex, and need to operate with greater reliability. In short, ships have to perform in more ways than buildings.
Architects have relied historically on the building expertise of the shipbuilders. Palladio designed the roof of the Basilica at the Piazza dei Signori in Vicenza (1617, figures 1.18a– b) as an inverted ship hull and had to bring shipbuilders from Venice to construct it. This reliance on the building skills of shipbuilders has continued to modern times. Buckminster Fuller in his Dymaxion House (1946, figures 1.19a–b) co-opted the production methods from aircraft and shipbuilding industries. Fuller’s design for the Dymaxion Car (1933,

Introduction 13
figures 1.20a–bving to work with the original structure in the garage belowb) employed methods for framing and cladding modeled after the ship hull construction, and was fabri- cated by a shipyard in Bridgeport, Connecticut.
  1.19a–b. Dymaxion House (1946), architect Buckminster Fuller.
1.20a–b. Dymaxion Car (1933), designer Buckminster Fuller.
Frank Gehry’s Guggenheim Museum in Bilbao would not have been possible without the local steel and shipbuilding industry. A number of other recently completed projects, of widely varying scales and budgets, made creative use of shipbuilder’s expertise. The Nat- West Media Centre at the Lord’s Cricket Ground in London (1999, figure 1.21), designed by Future Systems, was manufactured in a small shipyard in assembly at the building’s site. The shipbuilder’s expertise in making Cornwall, England (figure 1.22), and then trans- ported in segments for aluminum yacht hulls was essential in designing and manufacturing the first semi-monocoque building structure from aluminum (figure 1.23). The conference chamber in Frank Gehry’s DG Bank building (2000), Berlin, Germany, with its complex, curvilinear form, was clad in stainless steel plates produced and installed by skilled boat- builders.
   1.21. NatWest Media Centre (1999), Lord’s Cricket Ground, London, UK, architect Future Systems.

14 Architecture in the Digital Age
 1.22. NatWest Media Centre: aluminum shipyard.
Architects and builders have much more to learn from the shipbuilding industry. Shipbuild- ers have almost entirely eliminated drawings from the design and construction of ships, and are working instead with complete, comprehensive three-dimensional digital models from design to production (figure 1.24). Similar process changes have also taken place in automotive and aerospace industries. As in the building industry, they all work with numerous subcontractors to produce and assemble a large number of components with a high degree of precision. If we look beyond the complex, curved geometries of cars, planes and ships, which are increasingly becoming common in architecture as well, and focus on the centralized three-dimensional digital model, which is at the core of the transformation in those industries, the opportunities for architecture and the rest of the building industry become too apparent to ignore.
1.23. NatWest Media Centre: the semi-monocoque aluminum shell was made from 26 seg- ments.
1.24. An example of a comprehensive three-dimensional model used in the shipbuilding industry.

LEARNING FROM OTHERS
CAD/CAM systems, used by architects whose work is featured in this book, were actu- ally developed for the consumer product industry. Animation software, such as Softimage, Alias, and Maya, were developed for the special effects needs of the film industry.
This interest of architects in the re-use of technology and methods from other industries is nothing new. Architects have always looked beyond the boundaries of their discipline, appropriating materials, methods and processes from other industries as needed. Histori- cally, these technology transfers have been at the core of many successful advances, widen- ing the scope of innovation and continually affecting the prevalent norms of practice.
Today, much of the innovation and change stems from the adoption of digital design and production processes based on CAD/CAM processes, and from new materials invented for, and widely used in, the product design, automotive, aerospace and shipbuilding indus- tries.
1.25 The digital model of the Boeing 737.
The impact of the adoption of innovative technologies in those industries was profound— there was a complete reinvention of how products were designed and made. Today, various appliances, cars, airplanes and ships are entirely designed, developed, analyzed and tested in a digital environment, and are then manufactured using digitally-driven technologies. Boeing 777, “the first 100% digitally designed aircraft,” is probably one of the best-known examples (figure 1.25).
Buildings have that same potential to be digitally conceived and produced. While the CAD/CAM technological advances and the resulting changes in design and production techniques had an enormous impact on other industries, there has yet to be a similarly significant and industry-wide impact in the world of building design and construction. The opportunities for the architecture, engineering and construction (AEC) industries are beck- oning, and the benefits are already manifested in related fields.
Introduction 15

16 Architecture in the Digital Age
1 Ignasi de Sola Morales. Differences: Topographies of Contemporary Architecture. Cambridge:
MIT Press, 1997.
2 Peter Zellner. Hybrid Space: New Forms in Digital Architecture. New York: Rizzoli, 1999.
3 Gilles Deleuze. A Thousand Plateaus: Capitalism and Schizophrenia. Minneapolis: University of Minnesota Press, 1987.
4 Greg Lynn. “Architectural Curvilinearity: The Folded, the Pliant and the Supple” in Greg Lynn (ed.), AD Pro le 102: Folding in Architecture. London: Academy Editions, 1993, pp. 8–15.
5 Gilles Deleuze. The Fold: Leibniz and the Baroque. Minneapolis: University of Minnesota Press, 1992.
6 Rafael Moneo. “The Thing Called Architecture” in Cynthia Davidson (ed.), Anything. New York: Anyone Corporation, 2001, pp. 120–123.
7 Aline Saarinen (ed.). Eero Saarinen on His Work. New Haven: Yale University Press, 1968.
8 Ibid.
9 Bernard Cache. Earth Moves. Cambridge: MIT Press, 1995.
10 Ibid.
11 Ibid.
12 Peter Zellner. “Ruminations on the Perfidious Enchantments of a Soft, Digital Architecture, or: How I Learned To Stop Worrying And Love The Blob” in Peter C. Schmal (ed.), Digital, Real: Blobmeister First Built Projects. Basel: Birkhauser, 2001.
13 Reyner Banham. Theory and Design in the First Machine Age, 2nd edition. Cambridge: MIT Press, 1980.
14 Stephen Perrella (ed.). AD Pro le 133: Hypersurface Architecture. London: Academy Editions, 1998.
NOTES

2
DIGITAL MORPHOGENESIS
BRANKO KOLAREVIC
In contemporary architectural design, digital media is increasingly being used not as a rep- resentational tool for visualization but as a generative tool for the derivation of form and its transformation—the digital morphogenesis. In a radical departure from centuries-old traditions and norms of architectural design, digitally-generated forms are not designed or drawn as the conventional understanding of these terms would have it, but they are cal- culated by the chosen generative computational method. Instead of modeling an external form, designers articulate an internal generative logic, which then produces, in an auto- matic fashion, a range of possibilities from which the designer could choose an appropriate formal proposition for further development.
The predictable relationships between design and representations are abandoned in favor of computationally-generated complexities. Models of design capable of consistent, continual and dynamic transformation are replacing the static norms of conventional pro- cesses. Complex curvilinear geometries are produced with the same ease as Euclidean geometries of planar shapes and cylindrical, spherical or conical forms. The plan no longer “generates” the design; sections attain a purely analytical role. Grids, repetitions and sym- metries lose their past raison d’être, as infinite variability becomes as feasible as modular- ity, and as mass-customization presents alternatives to mass-production.
The digital generative processes are opening up new territories for conceptual, formal and tectonic exploration, articulating an architectural morphology focused on the emer- gent and adaptive properties of form. The emphasis shifts from the “making of form” to the “finding of form,” which various digitally-based generative techniques seem to bring about intentionally. In the realm of form, the stable is replaced by the variable, singularity by multiplicity.
TOPOLOGY
Computational, digital architectures are defined by computationally-based processes of form origination and transformations, i.e. the processes of digital morphogenesis, where the plural (“architectures”) emphasizes multiplicities inherent in the logics of the under- lying computational concepts, such as topological geometries, isomorphic polysurfaces (“blobs”), motionkinematics and dynamics, keyshape animation (metamorphosis), para- metric design, genetic algorithms (evolutionary architectures), performance, etc., which are discussed in more detail in the following sections.

18 Architecture in the Digital Age
The notion of topology has particular potentiality in architecture, as emphasis shifts away from particular forms of expression to relations that exist between and within an existing site and the proposed program. These interdependences then become the structur- ing, organizing principle for the generation and transformation of form.
According to its mathematical definition, topology is a study of intrinsic, qualitative prop- erties of geometric forms that are not normally affected by changes in size or shape, i.e. which remain invariant through continuous one-to-one transformations or elastic deformations, such as stretching or twisting. A circle and an ellipse, for example, or a square and a rectangle, can be considered to be topologically equivalent, as both circle and square could be deformed by stretching them into an ellipsoid or rectangle, respectively. A square and a rectangle have the same number of edges and the same number of vertices, and are, therefore, topologically identical, or homeomorphic. This quality of homeomorphism is particularly interesting, as focus is on the relational structure of an object and not on its geometry—the same topologi- cal structure could be geometrically manifested in an infinite number of forms (figure 2.1). Topological transformations, first and foremost, affect the relational structure, and, thus, the resulting form(s). For example, a rectangle could be transformed into a triangle with a single topological operation of deleting one of its vertices.
Because of their intrinsic property of one-sidedness, topological structures such as the Möbius strip1 (figure 1.12 in Chapter 1) and the Klein bottle2 (figure 1.13 in Chapter 1), have a potential for an architecture in which the boundaries between what is interior and what is exterior are blurred, an architecture that avoids the normative distinctions of “inside” and “outside.” While the conceptual possibilities of these topological geometries are intrigu- ing, their inherent, conceptual qualities are often difficult to truly manifest tectonically, as Möbius House (1995) by Ben Van Berkel and Caroline Bos shows to some extent. The transparent and solid boundaries of the shelter, which a house must provide, often work against the seamless continuities and erasure of inside/outside dichotomy imbued within the Möbius strip. What makes topology particularly appealing are not the complex forms, such as the Möbius strip, but the primacy over form of the structures of relations, intercon- nections or inherent qualities which exist internally and externally within the context of an architectural project.
2.1. Homeomorphic (topologically equivalent) figures.

Digital morphogenesis 19
Because topological structures are often represented by complex, curvilinear forms, topol- ogy is popularly—and wrongly—considered synonymous with curved surfaces. Another common misnomer is to refer to topologically produced geometries as “non-Euclidean.” As soon as a topological structure is given a geometric, architectonic form, the operative realm is firmly Euclidean. As the following section demonstrates, both Euclidean and non- Euclidean geometries are part of the same geometric universe, in which the Euclidean geometry is simply one special case, albeit one that has been firmly established in architec- tural thought and practice over the last few centuries.
2.2. Le Corbusier: volumetric composition in ancient architecture.
NON-EUCLIDEAN GEOMETRIES
Architectural thinking throughout centuries was based firmly on Euclidean thought and Platonic solids, neatly depicted in Le Corbusier’s sketch (figure 2.2) in his book Vers une architecture.3 The cylinder, pyramid, cube, prism and sphere were not only the essential forms of the Egyptian, Greek and Roman architecture, as dryly observed by Le Corbusier, but were also universal geometric “primitives” of the digital solid modeling software of the late twentieth century. They are no longer seen, however, as some kind of unique, isolated archetypes, but as special cases of quadric parametric surfaces.
Euclid’s Elements proposed five basic postulates of geometry, of which all were con- sidered self-evident except the fifth postulate of “parallelism,” which asserts that two lines are parallel, i.e. non-intersecting, if there is a third line that intersects both perpendicularly. The consequence of this postulate in Euclidean geometry is that through every point there is one and only one line parallel to any other line.
The first four postulates, as articulated by Euclid, are considered postulates of absolute geometry. It was this fifth postulate that opened the realm of non-Euclidean geometries. Though many had questioned Euclid’s fifth postulate, it was Carl Friedrich Gauss and the mathematicians after him who have finally managed to successfully demonstrate the existence of non-Euclidean geometries. The publication of Eugenio Beltrami’s seminal Essay on an Interpretation of Non-Euclidean Geometry in 1868 showed beyond doubt that curved lines could appear straight, that spherical geometry could seem planar, and that curved space could appear Euclidean, i.e. flat, thus turning the worlds of physics and astronomy upside down.4 Albert Einstein’s “Theory of Relativity,” based on non-Euclidean

20 Architecture in the Digital Age
geometry, powerfully showed how Newtonian physics, based upon Euclidean geometry, failed to consider the essential curvature of space.
The work of Gauss, Lobachevsky, Riemann, von Helmholtz, and other mathematicians and physicists later on, showed that space is not only curved but also multi-dimensional. By showing that geometries could be based on non-Euclidean relationships (such as paral- lelism, for example), they opened up other spatial possibilities disconnected from empiri- cal intuition.5 In Riemannian geometry, which is also known as “spherical” geometry, the “plane” is situated on the surface of a sphere, and the “line” is a circle that has the same radius as the sphere. For every two points, there is one and only one circle that connects them; as a consequence of this definition and the underlying spherical geometry, no parallel “lines” exist in Riemannian geometry, and every infinite “line,” i.e. circle, intersects every other infinite “line.” Also, the distance between two points is always a curved distance, i.e. not a “flat” distance. In Poincaré geometry, for example, “lines” are hyperbolas on a Car- tesian plane; there is an infinite number of “lines” through a chosen point that are parallel to another “line.”
Each of these non-Euclidean geometries has a particular application. Riemannian geometry is used in navigation, and Poincaré geometry is used in ballistics and for the representation of electromagnetic forces. What makes these and other non-Euclidean geometries interest- ing from an architectural point of view is the possibility of mapping objects between them, thus providing for a radically different conceptualization of space. Some modeling soft- ware, for example, provides for limited transformations of the Cartesian modeling space, which can approximate spatial characteristics of some of the non-Euclidean geometries.
Another interesting concept, which Bernhard Riemann introduced, is the concept of curvature of space and the spaces of positive and negative curvature. In this definition of space, Euclidean “flat,” planar space occupies the median position, having zero curvature. Euclidean geometry is then just a special kind of geometry, a special point on the infinite scale of bending, or folding, that produces “flatness” as a manifestation of an equilibrium that is established among various influences producing the curving of space in the first place. In other words, in the Riemannian conception of space, the “boxes” and “blobs” are simply instances on a sliding scale of formal complexity—a box could be turned into a blob and vice versa by simply varying the parameters of space within which they are defined.
  2.3. A composite curve constructed from tangent circular arcs and straight line segments.

Digital morphogenesis 21
As architectural conceptions of space move from the three dimensions of the Cartesian space to fourth-dimensional continuum of interactions between space and time, other dimensions and other conceptions of space begin to open up intriguing possibilities, which may or may not offer new potentialities for architectural thought. An architecture of warped multidimensional space would move beyond the mere manipulation of shapes and forms into the realm of events, influences and relationships of multiple dimensions.
NURBS
In pre-digital architecture, whose formal potentiality was, in large part, a direct extension of the limits of Euclidean geometry (lines, circles, quadrilaterals, etc.), the description and, consequently, the construction of compound, complex curves was accomplished through an approximation by concatenating tangent circular arcs and straight line segments (figure 2.3), which could be delineated with ease on paper and on the building site.
The introduction of digital modeling software into architectural design provided a departure from the Euclidean geometry of discrete volumes represented in Cartesian space and made possible the present use of “topological,” “rubber-sheet” geometry of continuous curves and surfaces that feature prominently in contemporary architecture. The highly cur- vilinear surfaces in the architecture of the digital avant-garde are described mathematically as NURBS, which is an acronym that stands for Non-Uniform Rational B-Splines. What makes NURBS curves and surfaces particularly appealing is their ability to easily control their shape by interactively manipulating the control points, weights and knots. NURBS make the heterogeneous, yet coherent, forms of the digital architectures computationally possible and their construction attainable by means of computer numerically controlled (CNC) machinery.
But why NURBS? The main reason for their widespread adoption is the ability of NURBS to construct a broad range of geometric forms, from straight lines and Platonic solids to highly complex, sculpted surfaces. From a computational point of view, NURBS provide for an efficient data representation of geometric forms, using a minimum amount of data and relatively few steps for shape computation, which is why most of today’s digital modeling programs rely on NURBS as a computational method for constructing complex surface models and, in some modelers, even solid models.
NURBS are a digital equivalent of the drafting splines used to draw the complex curves in the cross-sections of ship hulls and airplane fuselages. Those splines were flexible strips made of plastic, wood or metal that would be bent to achieve a desired smooth curve,
2.4. The shape of a NURBS curve can be changed by interactively manipulating the con- trol points, weights and knots.

22 Architecture in the Digital Age
with weights attached to them in order to maintain the given shape. The term spline (the “S” in NURBS) actually has its origin in shipbuilding, where it was used to refer to a piece of steamed wood shaped into a desired smooth curve and kept in shape with clamps and pegs. Mathematicians borrowed the term in a direct analogy to describe families of com- plex curves.
The shape of a NURBS curve can be changed by manipulating its control points and associated weights and knots (figure 2.4), as well as the degree of the curve itself (figure 2.5). The NURBS curves are shaped primarily by changing the location of control points, which do not have to lie on the curve itself, except for the endpoints. Each control point has an associated weight, which determines the extent of its influence over the curve, in a direct analogy to drafting splines. Increasing the weight of a control point pulls the corresponding curve or surface toward that control point and vice versa.
Each control point has an associated polynomial equation, commonly referred to as a basis function (the “B” in NURBS, and in B-splines in general). A rational B-spline (the “R” in NURBS) is defined mathematically as the ratio of two polynomial equations, i.e. two basis functions. Each basis function affects only the curve section in the vicinity of the associated control point, and these sections are delimited by knots. A non-uniform rational B-spline is one in which the influence of a control point (i.e. the associated basis function) on a curvature can be varied by changing the location of the knots along the control seg- ment that links two control points; in other words, a non-uniform rational B-spline is one with unequal knot spacing.
2.5. Varying the degree of a NURBS curve will produce different shapes.
2.6. Curvature graph for a cubic Bezier spline.
Another important parameter that can affect the shape of a NURBS curve is the degree, i.e. the highest exponent within the polynomial equations associated with control points. The lower the polynomial degree, the closer the curve is placed towards the control points. Thus, the second degree (quadratic) basis functions would pull the curve closer to control points than the third degree (cubic) ones (figure 2.5). The first degree (linear) functions produce a “curve” with straight line segments.

Digital morphogenesis 23
Other spline curves, as subcategories of NURBS, are typically available in model- ing software. B-splines are actually NURBS with equally weighted control points (thus, weights are not displayed). Bézier curves, named after Pierre Bézier, the French automo- tive engineer who invented them, are B-splines with equal knot spacings (thus, knots are not shown). Cubic curves are actually third-degree continuous Bézier curves, and quadratic curves are second-degree continuous Bézier curves. In this pseudo-taxonomy of spline curves, at each level an additional set of controls over curvature is lost: weights in the case of B-splines, and both weights and knots in the case of Bézier curves.6
An important property of curves made by splines is that their curvature, i.e. the curve radius, changes continually along their length, in sharp contrast to curves made of tangent circular arcs, which, despite their smooth appearance, have discrete points at which the curvature changes abruptly. There are different levels of curvature continuity (figure 2.6): a curve with an angle or a cusp is said to have CO continuity;7 a curve without cusps but with changing curvature has C1 continuity;8 a curve with constant curvature is C2 continu- ous9—higher levels of continuity are possible, but for most practical purposes, these three levels are sufficient. Besides fluid dynamics, the curvature continuity also has important aesthetic and manufacturing implications, which is why most modeling programs provide tools for the continuity analysis (figures 2.7 and 2.8).
The location of control points in a NURBS curve can affect its continuity locally, mean- ing that different segments can have different levels of continuity. For instance, two coin- cident control points in a NURBS curve would pronounce the curvature; three coincident control points would produce an angular cusp. This potentiality of NURBS curves of hav- ing varying continuity is referred to as multiplicity.
The definition of NURBS surfaces is a straightforward extension of NURBS curves. A control lattice that connects control points surrounds the surface (figure 2.9). Each control point has an associated weight parameter, and knots control the distribution of the local influence as in curves. In other words, the shape of a NURBS surface can be manipulated in the same ways as in curves.
2.7. Curvature continuity: the zebra analysis.
2.8. Curvature continuity: the Gaussian analysis.

24 Architecture in the Digital Age
Another property of NURBS objects, which is of particular importance from a conceptual point of view, is that they are defined within a “local” parametric space, situated in the three-dimensional Cartesian geometric space within which the objects are represented.10 That parametric space is one-dimensional for NURBS curves, even though the curves exist in a three-dimensional geometric space. That one-dimensionality of curves is defined at a topological level by a single parameter commonly referred to as “U.” Surfaces have two dimensions in the parametric space, often referred to as “U” and “V” in order to distinguish them from X, Y and Z of the Cartesian three-dimensional geometric realm. Isoparametric curves (“isoparms”) are used to aid in the visualizing of NURBS surfaces through con- touring in the “U” and “V” direction (figure 2.10). These curves have a constant U or V parameter in the parametric NURBS math, and are similar to topographic contour lines that are used to represent constant elevations in landscape.
 2.9. The control lattice for a NURBS surface.
The parametric description of forms (parametrics) provides a particularly versatile way to represent complex curves and surfaces. Sets of equations are used to express certain quantities as explicit functions of a number of variables, i.e. parameters, which can be independent or dependent. For instance, one set of parametric equations for a circle in two-dimensional Cartesian coordinate space could be given as x=r×cos t and y = r×sin t, whereby the parameter t is the inscribed angle whose value can range from 0 to 2π (figure 2.11). Parametric representations are generally non-unique, i.e. the same quantities can be expressed by a number of different parameterization strategies (for example, the equation r2=x2+y2 is another way to describe the geometry of the circle).
 2.10. Isoparametric contours in the “U” direction of a NURBS surface.

PARAMETRICS
Parametrics can provide for a powerful conception of architectural form by describing a range of possibilities, replacing in the process stable with variable, singularity with mul- tiplicity. Using parametrics, designers could create an infinite number of similar objects, geometric manifestations of a previously articulated schema of variable dimensional, rela- tional or operative dependencies. When those variables are assigned specific values, par- ticular instances are created from a potentially infinite range of possibilities.
Digital morphogenesis 25
 2.11. Parametric definition of a circle.
In parametric design, it is the parameters of a particular design that are declared, not its shape. By assigning different values to the parameters, different objects or configurations can be created. Equations can be used to describe the relationships between objects, thus defining an associative geometry—the “constituent geometry that is mutually linked.”11 That way, interdependencies between objects can be established, and objects’ behavior under transformations defined. As observed by Burry, “the ability to define, determine and reconfigure geometrical relationships is of particular value.”12
2.12a–d. Paracube by Marcos Novak.
Parametric design often entails a procedural, algorithmic description of geometry. In his “algorithmic spectaculars” (figures 2.12a–d), i.e. algorithmic explorations of “tectonic production” using Mathematica software, Marcos Novak constructs “mathematical mod- els and generative procedures that are constrained by numerous variables initially unrelat- ed to any pragmatic concerns... Each variable or process is a ‘slot’ into which an external influence can be mapped, either statically or dynamically.”13 In his explorations, Novak is “concerned less with the manipulation of objects and more with the manipulation of relations,

26 Architecture in the Digital Age
fields, higher dimensions, and eventually the curvature of space itself.”14 The implication is that the parametric design does not necessarily predicate stable forms. As demonstrated by Burry, one can devise a paramorph—an unstable spatial and topological description of form with stable characteristics (figure 2.13).
The International Terminal at Waterloo Station in London (1993, figure 2.14), by Nich- olas Grimshaw and Partners, offers a clear demonstration of conceptual and developmental benefits afforded by the parametric approach to design. The building is essentially a 400 m long glass-clad train shed, with a “tapering” span that gradually shrinks from 50 m to 35 m. Its narrow, sinuous plan is determined by the track layout and the difficult geometry of the site, which is the main source of the project’s complexity and which gives such potency and significance to Grimshaw’s design, especially its spectacular roof structure.
2.13. Paramorph by Mark Burry.
The roof structure consists of a series of 36 dimensionally different but identically config- ured three-pin bowstring arches (figure 2.15). Because of the asymmetrical geometry of the platforms, the arches rise steeply on one side with a shallower incline over the platforms on the other side. Each arch is different as the width of the roof changes along the tracks.
Instead of modeling each arch separately, a generic parametric model was created based on the underlying design rules in which the size of the span and the curvature of individual arches were related (figures 2.16a-b). By assigning different values to the span parameter, 36 dimensionally different, yet topologically identical, arches were computed and inserted in the overall geometric model.
The parametric model could be extended from the structural description of arches to the elements that connect them, the corresponding cladding elements, i.e. to the entire build- ing form. Thus, a highly complex hierarchy of interdependences could be parametrically modeled, allowing iterative refinement, i.e. the dimensional fine-tuning of the project in all stages of its development, from conceptual design to construction.
As shown by this project, parametrics are particularly useful for modeling the geom- etry of complex building forms. Their successful application requires careful articula- tion of a clear strategy of tectonic resolution, such that a sufficiently clear description of

Digital morphogenesis 27
interdependences can be achieved; in other words, a well-defined design strategy is essen- tial for the effective application of parametrics.
Parametric approach to design, if consistently applied from its conceptual phase to its materialization, profoundly changes the entire nature and the established hierarchies of the building industry, as well as the role of the architect in the processes of building. For the first time in history, architects are designing not the specific shape of the building but a set of principles encoded as a sequence of parametric equations by which specific instances of the design can be generated and varied in time as needed. Parametric design calls for the rejection of fixed solutions and for an exploration of infinitely variable potentialities.
2.14. International Terminal, Waterloo Station (1993), London, UK, architect Nicholas Grimshaw and Partners.
2.15. International Terminal, Waterloo Station: 36 dimensionally different but identically configured three-pin bowstring arches.

28 Architecture in the Digital Age
  2.16a–b. Parametric definition of the scaling factor for the truss geometry: h = ((29152 + (B
x
As Greg Lynn observed in Animate Form,15 “it is important for any parameter-based design that there be both the unfolding of an internal system and the infolding of contextual infor- mation fields.” Architectural form, in other words, is not only a manifestation of its inter- nal, parameter-driven relational logics, but it also has to engage and respond to dynamic, often variable influences from its environmental and socio-economic context. Architectural form, instead of being conceived as a stationary, inert construct, is conceptually a highly plastic, mutable entity that evolves dynamically through its transformative interactions with external, gradient forces. According to Lynn, in place of a neutral abstract space, “the context of design becomes an active abstract space that directs from within a current of forces that can be stored as information in the shape of the form.”16
Greg Lynn was one of the first architects to utilize animation software not as a medium of representation, but of form generation. He asserts that the prevalent “cinematic” model of motion in architecture eliminates force and motion from the articulation of form and reintroduces them later, after the fact of design, through concepts and techniques of optical procession. In contrast, as defined by Lynn, “animate design is defined by the co-presence of motion and force at the moment of formal conception.”17 Force, as an initial condition, produces as its effects both motion and particular inflections of form. According to Lynn, “while motion implies movement and action, animation implies evolution of a form and its shaping forces.”18
+ C)2)1⁄2, where B is the minor truss span and C is the major truss span.
DYNAMICS AND FIELDS OF FORCES

Digital morphogenesis 29
In his seminal projects, showcased in Animate Form, Lynn utilizes an entire repertoire of motion-based modeling techniques, such as keyframe animation, forward and inverse kinematics, dynamics (force fields), and particle emission. Kinematics, in its true mechani- cal meaning, is used to study the motion of an object or a hierarchical system of objects
2.17a–c. Inverse kinematics is used in the House Prototype in Long Island project, archi- tect Greg Lynn.
2.18a–d. The use of particle emission in the Port Authority Bus Terminal in New York competition project, architect Greg Lynn.

30 Architecture in the Digital Age
without consideration given to its mass or the forces acting on it. Hierarchical constructs, such as “skeletons” made of “bones” and “joints,” which can have various associated con- straints, allow designers to create an infrastructure of relations that determine the complex behavior of the model under transformations, which, for example, can result from the influ- ence of external forces. A “global skin” assigned to such “skeletal” hierarchical organiza- tions makes the deformations formally manifestable. As motion or external influences are applied, transformations are propagated down the hierarchy in forward kinematics, and upwards in inverse kinematics. In some of Lynn’s projects, such as the House Prototype in Long Island (figures 2.17a–c), skeletons with a global envelope are deformed using inverse kinematics under the influence of various site-induced forces.
In contrast to kinematics, the dynamic simulation takes into consideration the effects of forces on the motion of an object or a system of objects, especially of forces that do not originate within the system itself. Physical properties of objects, such as mass (density), elasticity, static and kinetic friction (or roughness), are defined. Forces of gravity, wind, or vortex are applied, collision detection and obstacles (deflectors) are specified, and dynamic simulation computed. Gradient field influences are applied as direct abstract analogies for environmental influences, such as wind and sun, and contextual phenomena, such as pedes- trian and vehicular movements, urban vistas, configurations, patterns and intensities of use, etc. Greg Lynn’s design of a protective roof and a lighting scheme for the bus terminal in New York (Figures 2.18a–d) offers a very effective example of using particle systems to visualize the gradient fields of “attraction” present on the site, created by the forces associ- ated with the movement and flow of pedestrians, cars and buses across the site.
The incorporation of movement into what was, by definition, static and unmovable is nothing new—it was one of the ideals of modern architecture. However, the architecture that was described by modernists as embodying movement simply promoted movement through its interior and exterior, becoming, as observed by Ignasi de Sola Morales, “above all a space for mobility, a container in which movement was prefigured.”19
2.19. Form can be generated by subjecting the basic structures to force fields extrapolated from the context of the project (“Dynaform,” architect Bernhard Franken).
2.21a–b. The interacting “drops of water” (blobs) and the translation into a built form: The “Bubble,” BMW’s exhibition pavilion at the IAA ’99 Auto Show in Frankfurt, Germany, architects Bernhard Franken and ABB Architekten.

2.20. Isomorphic polysurfaces.
The architecture of motion, therefore, is not the same as the architecture of movement.20 It prioritizes form over space by introducing the motion and force at the moment of formal conception.21 It is the dynamics of forces, or, more precisely, force fields, as an initial con- dition that produces the motion and the particular transformations of form, i.e., the digital morphogenesis (figure 2.19). The form and its changes become products of the dynamic action of forces, a proposition adopted by Lynn directly from D’Arcy Thompson’s On Growth and Form, published in 1917, in which Thompson argues that the form in nature and the changes of form are due to the “action of force.”22 One of Lynn’s principal argu- ments is that “traditionally, in architecture, the abstract space of design is conceived as an ideal neutral space of Cartesian coordinates,” but that in other design fields, “design space is conceived as an environment of force and motion rather than as a neutral vacuum.”23 According to Lynn, “while physical form can be defined in terms of static coordinates, the virtual force of the environment in which it is designed contributes to its shape,”24 thus making the forces present in the given context fundamental to the form making in archi- tecture. Lynn attributes to this position the significance of a paradigm shift “from a passive space of static coordinates to an active space of interactions,” which he describes as “a
2.22. Wozoco’s Apartments (1997), Amsterdam-Osdorp, the Netherlands, architect MVRDV.
Digital morphogenesis 31

32 Architecture in the Digital Age
move from autonomous purity to contextual specificity.”25 Instrumental to this conceptual shift is the use of digital media, such as animation and special-effects software, which Lynn uses as tools for design rather than as devices for rendering, visualization and imaging.
Instead of subjecting generic formal constructs to the influences of force fields, designers could directly visualize the shape of the force fields using isomorphic polysurfaces, which represent yet another point of departure from Platonic solids and Cartesian space. Blobs or metaballs, as isomorphic polysurfaces are sometimes called, are amorphous objects con- structed as composite assemblages of mutually-inflecting parametric objects with internal forces of mass and attraction. They exercise fields or regions of influence (figure 2.20), which could be additive (positive) or subtractive (negative). The geometry is constructed by computing a surface at which the composite field has the same intensity—hence the name isomorphic polysurfaces.
Isomorphic polysurfaces open up yet another formal universe where forms may undergo variations, giving rise to new possibilities. Objects interact with each other instead of just occupying space; they become connected through a system of interactions where the whole is always open to variations as new blobs (fields of influence) are added or new relations made, creating new possibilities. The surface boundary of the whole (the isomorphic poly- surface) shifts or moves as fields of influence vary in their location and intensity (figures 2.21a–b). In that way, objects begin to operate in a temporally-conditioned dynamic, rather than a static geography.
DATASCAPES
With his pioneering work on using motion dynamics to generate architectural form, Lynn has convincingly demonstrated what Nicholas Negroponte had only hinted at in his semi- nal work from some 30 years ago, The Architecture Machine, and which is also acknowl- edged in Lynn’s writing:
“Physical form, according to D’Arcy Thompson, is the resolution at one instant of time of many forces that are governed by rates of change. In the urban context the complexity of these forces often surpasses human comprehension. A machine, meanwhile, could procre- ate forms that respond to many hereto un-manageable dynamics. Such a colleague would not be an omen of professional retirement but rather a tickler of the architect’s imagination, presenting alternatives of form possibly not visualized or not visualizable by the human designer.”26
Buildings and projects in general are conceived within a complex web of planning and building regulations (which are by no means fixed constructs), various technical con- straints, environmental conditions, such as sun, wind, precipitation, etc., and are meant to operate in a highly dynamic socio-economic and political context, which has its own “force fields” such as, for instance, numerous interest groups. Some of these influences could be quantified and their changes modeled in order to simulate past, and predict present and future, impact.

2.24a–d. Deformation diagrams for Bibliothèque de L′IHUEI (1996–), University of Geneva, Switzerland, architect Peter Eisenman.
2.23. Üstra Of ce Building (1999), Hanover, Germany, architect Frank Gehry.
The design approach of the Dutch firm MVRDV acknowledges explicitly the existence of these “gravity fields” and their principal role in the shaping of the built environment (figure 2.22). In order to harvest the informational potential of the complexities inherent in various forces and the complex web of their interactions, MVRDV came up with the concept of datascapes,27 which are visual representations of quantifiable forces that could influence or impact the conception and development of design projects. These informational landscapes become essential in understanding how these intangible influences manifest themselves in the built environment and how societal, economic, political and cultural fluxes and shifts influence contemporary architecture.
In MVRDV’s approach, for each influence a separate datascape is constructed. Various datascapes, relevant for the selected context, are then superposed, creating a complex spa- tial envelope, with often contradictory, paradoxical conditions, which embodies within its limits the inherent possibilities for the genesis of an architectural project. The challenge, of course, is how to avoid a literal transcription of the diagrams of contextual flows and forces into an architectural form, as the superposition of datascapes, static or dynamic, often gen- erates spatial and temporal constructs with apparent architectonic qualities.
Digital morphogenesis 33

34 Architecture in the Digital Age
 2.26. The Ost/Kuttner Apartments (1996), New York, USA, architect Kolatan and Mac Donald.
METAMORPHOSIS
Digital modeling software offers a rich repertoire of transformations a designer could use to further explore formal potentialities of an already conceived geometry. Simple, topo- logically invariant transformations, such as twisting and bending, are particularly effective means for creating alternative morphologies. For instance, Gehry’s Üstra Of ce Building in Hanover, Germany (1999), has a simple prismatic form, which twists in the direction of the nearby open park area (figure 2.23).
By adding a fourth, temporal dimension to the deformation processes, animation soft- ware adds a possibility to literally express the space and form of an object’s metamor- phosis. In keyshape (keyframe) animation, different states of an object (i.e. keyshapes or keyframes) are located at discrete points in time, and the software then computes through interpolation a smooth, animated, time-encoded transition between them. A designer could choose one of the interpolated states for further development, or could use the interpolation as an iterative modeling technique to produce instances of the object as it transitions, i.e. morphs from one state to another (figures 2.24a–d).
A particularly interesting temporal modeling technique is morphing, in which dissimilar forms are blended to produce a range of hybrid forms that combine formal attributes of the “base” and “target” objects. Kolatan and Mac Donald used morphing in a number of their

2.27. Ost/Kuttner Apartments: the “cross-section referencing” diagram.
2.25a–e. Kolatan and Mac Donald’s “chimerical” Housings project.
2.28. Path animation: four rectilinear volumes move along four separate curved paths.
Digital morphogenesis 35

36 Architecture in the Digital Age
projects. In Housings, a normative three-bedroom, two-and-a-half bathroom colonial house was used as a “base” object that was then morphed into a range of everyday objects as “tar- gets,” producing a large range of what they call “chimerical” designs (figures 2.25a-e). In the Ost/Kuttner Apartments (1996, figure 2.26), they digitally blended cross-referenced sectional profiles of common household furniture, such as a bed, sink, sofa, etc., to gener- ate new hybrid forms that establish a “chimerical condition between furniture, space, and surface”28 (figure 2.27). Kolatan and Mac Donald intentionally employed digital generative processes whose outcomes were “unknown and impossible to preconceive or predict,”29 i.e. they relied on processes characterized by non-linearity, indeterminacy and emergence, which are discussed later in this chapter.
Other techniques for the metamorphic generation of form include deformations of the modeling space around an object using a bounding box (lattice deformation), a spline curve, or one of the coordinate system axes or planes, whereby an object’s shape conforms to the changes in geometry of the modeling space. In path animation, for example, an object is deformed as it moves along a selected path (figure 2.28).
2.29. Interactivator (1995) by John and Julia Frazer: experimental evolution of form by interaction with actual visitors and environmental sensors (programming by Manit Ras-
togi, Patrick Janssen and Peter Graham).
GENETICS
The “rules” that direct the genesis of living organisms, that generate their form, are encoded in the strands of DNA. Variation within the same species is achieved through gene crossover and mutation, i.e. through the iterative exchange and change of information that governs the biological morphogenesis.

Digital morphogenesis 37
The concepts of biological growth and form, i.e. the evolutionary model of nature, can be applied as the generative process for architectural form as well, argues John Frazer in his book Evolutionary Architecture.30 According to Frazer, architectural concepts are expressed as a set of generative rules, and their evolution and development can be digitally encoded. The generative script of instructions produces a large number of “prototypical forms which are then evaluated on the basis of their performance in a simulated environment.”31 Accord- ing to Frazer, the emergent forms are often unexpected.
The key concept behind the evolutionary approach to architecture is that of the genetic algorithm, “a class of highly parallel evolutionary, adaptive search procedures,” as defined by Frazer. Their key characteristic is a “a string-like structure equivalent to the chromo- somes of nature,” to which the rules of reproduction, gene crossover and mutation are applied. Various parameters are encoded into “a string-like structure” and their values
 2.30. X Phylum project by Karl Chu.
changed, often randomly, during the generative process. A number of similar forms, “pseudo-organisms,” are generated (figure 2.29), which are then selected from the gener- ated populations based on a predefined “fitness” criteria. The selected “organisms,” and the corresponding parameter values, are then crossbred, with the accompanying “gene crossovers” and “mutations” thus passing “beneficial and survival-enhancing traits” to new generations. Optimum solutions are obtained by small incremental changes over several generations.
 2.31. The FEM analysis for the fabric envelope of “Dynaform,” BMW Pavilion at the IAA’01 Auto Show in Frankfurt, Germany, architects Bernhard Franken and ABB
Architekten.

38 Architecture in the Digital Age
Karl Chu’s approach to digital morphogenesis and to what he calls the “proto-bionic” architecture is a formal system based on the generative logic of the Lindermayer System (L-System)32 and its implementation in digital modeling software, where it is used for the simulation of plant growth. L-systems are based on a recursive, rule-based branching system, conceived on the simple technique of rewriting, in which complex objects are cre- ated by successively replacing parts of an initially constructed object using a set of simple rewriting rules. The generative rules of an L-system can be very succinctly expressed. A simple set of carefully defined rules can produce a very complex object in a recursive pro- cess consisting of only a few levels (figure 2.30).
In both approaches to generative design based on biological metaphors, the task of the architect is to define the common source of form, the “genetic coding” for a large family of similar objects, in which variety is achieved through different processes of “reproduction.” As was the case with other contemporary approaches to design, in processes of genetic coding the emphasis shifts to articulating the inner logic of the project rather than the external form.
2.32. The FEM analysis for the glass envelope of the “Bubble,” BMW Pavilion at the IAA’99 Auto Show in Frankfurt, Germany, architects Bernhard Franken and ABB Archi-
tekten.
2.33. Project ZED (1995), London, UK, architect Future Systems.

Digital morphogenesis 39 PERFORMATIVE ARCHITECTURE
Another kind of architecture is also emerging, using building performance as a guiding design principle and adopting a new list of performance-based priorities for the design of cities, buildings, landscapes and infrastructures. This new kind of architecture places broadly defined performance above form-making; it utilizes the digital technologies of quantitative and qualitative performance-based simulation to offer a comprehensive new approach to the design of the built environment.
In this new information- and simulation-driven design context, the emerging paradigm of performance-based design is understood very broadly—its meaning spans multiple realms, from financial (the owner’s perspective), spatial, social and cultural to purely tech- nical (structural, thermal, acoustical, etc.). The emphasis on building performance (again, broadly understood from the financial, spatial, social, cultural, ecological and technical perspective) is redefining expectations of the building design, its processes and practices.
2.34. The CFD analysis of wind flows for Project ZED (1995), London, UK, architect Future Systems.
2.35. Kunsthaus (2003), Graz, Austria, architects Peter Cook and Colin Fournier.

40 Architecture in the Digital Age
Analytical computational techniques based on the finite-element method (FEM), in which the geometric model is divided into small, interconnected mesh elements, are used to accurately perform structural, energy and fluid dynamics analyses for buildings of any formal complexity. These quantitative evaluations of specific design propositions can be qualitatively assessed today thanks to improvements in graphic output and visualization techniques (figures 2.31 and 2.32). By superposing various analytical evaluations, design alternatives could be compared with relative simplicity to select a solution that offers opti- mal performance.
In computational fluid dynamics (CFD) software, used mainly to analyze airflows within and around buildings, fluid flow physics are applied to the digital model of a building to compute not only the dynamic behavior of the fluids (air, smoke, water, etc.), but also the transfer of heat mass, phase change (such as the freezing of water), chemical reactions (such as combustion), and stress or deformation of building structure (in fire, etc.).
Future Systems, a design firm from London, used CFD analysis in a particularly inter- esting fashion in its Project ZED, the design of a multiple-use building in London (1995, figure 2.33). The building was meant to be self-sufficient in terms of its energy needs by incorporating photovoltaic cells in the louvers and a giant wind turbine placed in a huge hole in its center. The curved form of the façade was thus designed to minimize the impact of the wind at the building’s perimeter and to channel it towards the turbine at the center. The CFD analysis was essential in determining the optimal performance of the building envelope (figure 2.34).
The original blobby shape of Peter Cook’s and Colin Fournier’s competition winning entry for the Kunsthaus in Graz, Austria (2003, figure 2.35), was altered somewhat after the digital structural analysis, by consulting engineers Bollinger + Grohmann from Frankfurt, revealed that its structural performance could be improved with minor adjustments in the overall form. Likewise, Foster and Partners’ design for the main chamber of the Greater London Authority (GLA) Headquarters (2002, figure 2.36) had to undergo several signifi- cant changes after engineers from Arup analyzed its acoustical performance using in-house developed acoustic wave propagation simulation software (figure 2.37). It is interesting to note that the “pebble”-like form of the building resulted from optimizing its energy perfor- mance by minimizing the surface area exposed to direct sunlight (figure 2.38). The building’s
2.36. GLA Headquarters: (2002), London, UK, architect Foster and Partners.

2.37. GLA Headquarters: one of the acoustical studies (by Arup).
2.38. GLA Headquarters: one of the solar studies (by Arup).
“blobby” form is actually a deformed sphere, which has a 25% smaller surface area than a cube of identical volume, resulting in a reduced solar heat gain and heat loss through the building’s skin. The cladding configuration was a direct outcome of the analysis of sunlight patterns throughout the year.
Foster’s performative approach to the design of the GLA building could imply a sig- nificant shift in how “blobby” forms are perceived. The sinuous, highly curvilinear forms could become not only an expression of new aesthetics, or a particular cultural and socio- economic moment born out of the digital revolution, but also an optimal formal expression for the new ecological consciousness that calls for sustainable building. If wind turbines were to become a reality of mankind’s future, as futuristic designs by Future Systems sug- gest, the built environment would attain new morphology in which “boxes” could become as exotic as “blobs” are today.
Although digital technologies, in particular performance-based simulations, have made the notion of performative architecture possible, challenges and opportunities do exist in the ways these technologies are being conceptualized and used. Instead of being used in
Digital morphogenesis 41

42 Architecture in the Digital Age
a passive, “after-the-fact” fashion, i.e. after the building form has been articulated, as is currently the case, analytical computation could be used to actively shape the buildings in a dynamic fashion, in a way similar to how animation software is used in contemporary architecture. An already-structured building topology, with a generic form, could be sub- jected to dynamic, metamorphic transformation, resulting from the computation of per- formance targets set at the outset. This dynamic range of performative possibilities would contain, at one end, an unoptimized solution and, at the other end, an optimized condition (if it is computable), which might not be an acceptable proposition from an aesthetic, or some other, point of view. In that case, a sub-optimal solution could be selected from the in-between performative range, which could potentially satisfy other non-quantifiable per- formative criteria.
This new kind of analytical software would preserve the topology of the proposed schematic design but would alter the geometry in response to optimizing a particular per- formance criteria (acoustic, thermal, etc.). For example, if there is a particular geometric configuration comprised of polygonal surfaces, the number of faces, edges, and vertices would remain unchanged (i.e. the topology does not change), but the shapes (i.e. the geom- etry) would be adjusted (and some limits could be imposed in certain areas). The process of change could be animated, i.e. from the given condition to the optimal condition, with the assumption that the designer could find one of the in-between conditions interesting and worth pursuing, even though it may not be the most optimal solution.
NON-LINEARITY, INDETERMINACY AND EMERGENCE
Contemporary approaches to architectural design have abandoned the determinism of tra- ditional design practices and have embraced the directed, precise indeterminacy of new digital processes of conception. Instead of working on a parti, the designer constructs a generative system of formal production, controls its behavior over time, and selects forms that emerge from its operation. In this model of design, a system of influences, relations, constrains or rules is defined first through the processes of in-formation, and its tempo- ral behavior is specified; the resulting structure of interdependences is often given some generic form (formation), which is then subjected to the processes of de-formation or transformation, driven by those very same relations, influences or rules imbedded within the system itself.
The new approaches to design open up a formal universe in which essentially curvi- linear forms are not stable but may undergo variations, giving rise to new possibilities, i.e. the emergent form. The formal complexity is often intentionally sought out, and this morphological intentionality is what motivates the processes of construction, operation and selection. The designer essentially becomes an “editor” of the morphogenetic poten- tiality of the designed system, where the choice of emergent forms is driven largely by the designer’s aesthetic and plastic sensibilities. The capacity of digital, computational architectures to generate “new” designs is, therefore, highly dependent on the designer’s perceptual and cognitive abilities, as continuous, dynamic processes ground the emer- gent form, i.e. its discovery, in qualitative cognition. Even though the technological con- text of design is thoroughly externalized, its arresting capacity remains internalized. The

Digital morphogenesis 43
generative role of new digital techniques is accomplished through the designer’s simulta- neous interpretation and manipulation of a computational construct (topological surface, isomorphic field, kinetic skeleton, field of forces, parametric model, genetic algorithm, etc.) in a complex discourse that is continuously reconstituting itself-a “self-reflexive” discourse in which graphics actively shape the designer’s thinking process. For instance, designers can see forms as a result of reactions to a context of “forces” or actions, as demonstrated by Greg Lynn’s work. There is, however, nothing automatic or deterministic in the defini- tion of actions and reactions; they implicitly create “fields of indetermination” from which unexpected and genuinely new forms might emerge; unpredictable variations are generated from the built multiplicities.
It is precisely the ability of “finding a form” through dynamic, highly non-linear, inde- terministic systems of organization that gives digital media a critical, generative capacity in design. Non-linear systems change indeterminately, continually producing new, unex- pected outcomes. Their behavior over time cannot be explained through an understanding of their constituent parts, because it is the complex web of interdependencies and interac- tions that define their operation. In addition, in non-linear systems, it is often the addition or subtraction of a particular kind of information that can dramatically affect its behavior—in other words, a small quantitative change can produce a disproportionally large qualitative effect. It is this inherent capacity for “threshold” behavior that assigns to non-linearity the qualities of emergent behavior and infinite potential for change.
By openly embracing non-linearity, indeterminacy and emergence, the new digital design techniques challenge conventions such as stable design conceptualization, mono- tonic reasoning and first order logic that were (and still are) the underlying foundation for the design of mainstream computational tools for architectural production. In contempo- rary computational approaches to design, there is an explicit recognition that admittance of the unpredictable and unexpected is what often paves the way to poetic invention and creative transformation. The non-linearity, indeterminacy and emergence are intentionally sought out.
IT IS NOT ABOUT “BLOBS”
The changes brought about by the Information Age and globalization, as its most radical manifestation, are having a dramatic and profound impact on societies, economies and cultures worldwide. Architects, as they have done for centuries, are trying to interpret these changes and find an appropriate expression for an architecture that captures the zeitgeist of the dawn of the Information Age, which befits the information revolution and its effects. There is a wide range of approaches, discussed in this chapter, all of which express the unprecedented generative potentiality of digital techniques. The “blobby” aesthetics, which seem to be pervasive in the projects of the avant-garde, are often sidetracking the critical discourse into the more immediate territory of formal expression and away from more fun- damental possibilities that are opening up, such as the opportunity for architects to reclaim the lost ground and once again become fully engaged in the act of building (as information master-builders). This is not to say that the profession should not maintain a critical attitude towards the potentiality of the digital, but that it should attempt to see beyond the issues of

44 Architecture in the Digital Age
the formal aesthetics. Some extravagant claims were made, of course, and some unreason- able expectations were projected, which is not surprising given the totalizing fashion with which the digital domain is embraced in certain academic circles. But speculative design work, enabled by digital technologies, should at least provoke a healthy debate about the possibilities and challenges of the digital future.
Obviously, the “blobs” will not have a significant impact on architecture’s future if they are understood in formal terms alone, or if they are seen as utopian architectural visions, as already happened in the 1960s. The challenge for the profession is to understand the appearance of the digitally-driven generative design and production technologies in a more fundamental way than as just tools for producing “blobby” forms.
NOTES
1 The Möbius strip, named after August Möbius, the German mathematician who first published this single-sided figure in 1865, can be simply constructed by connecting two ends of a twisted linear strip.
2 The Klein bottle is an edgeless, self-intersecting surface.
3 Le Corbusier. Towards a New Architecture (translated by F. Etchells). New York: Dover Publica-
tions, 1931.
4 Roberto Bonola. Non-Euclidean geometry: A Critical and Historical Study of its Development (translated by H.S.Carslaw). New York: Dover Publications, 1955.
5 Ibid.
6 It is important to note, however, that unequally weighted control points become necessary for
constructing the curves of conic sections: circles, ellipses, parabolas, and so on.
7 Mathematically, this means that the curve is continuous but has no derivative at the cusp.
8 The first derivative is continuous, but the second one is not.
9 Both the first and second derivatives are continuous.
10 For more information about NURBS parametric definition, see Les Piegl and Wayne Tiller, The NURBS Book, 2nd edition. New York: Springer, 1997.
11 Mark Burry. “Paramorph” in Stephen Perrella (ed.), AD Pro le 141: Hypersurface Architecture II. London: Academy Editions, 1999.
12 Ibid.
13 Marcos Novak. “Transarchitectures and Hypersurfaces” in Stephen Perrella (ed.), AD Pro le 133:
Hypersurface Architecture. London: Academy Editions, 1998.
14 Ibid.
15 Greg Lynn. Animate Form. Princeton: Princeton Architectural Press, 1998.
16 Ibid.
17 Ibid.
18 Ibid.
19 Ignasi de Sola Morales. Differences: Topographies of Contemporary Architecture. Cambridge: MIT Press, 1997.

20 Lynn, Animate Form. op cit.
21 Ibid.
22 D’Arcy Thompson. On Growth and Form. Cambridge (UK): Cambridge University Press, 1917.
23 Lynn. Animate Form. op cit
24 Ibid.
25 Ibid.
26 Nicholas Negroponte. The Architecture Machine. Cambridge: MIT Press, 1970.
27 MVRDV. Metacity/Datatown. Rotterdam, the Netherlands: 010 Publishers, 1999.
28 Sulan Kolatan. “More Than One/Less Than Two_RESIDENCE[S]” in Peter C. Schmal (ed.), Digital, Real: Blobmeister First Built Projects. Basel: Birkhauser, 2001. pp. 68–79.
29 Ibid.
30 John Frazer. Evolutionary Architecture. London: Architectural Association, 1995.
31 Ibid.
32 A mathematical theory of plant development named after its inventor, biologist Aristid Linden- mayer (1925–89).
Digital morphogenesis 45

3
DIGITAL PRODUCTION
BRANKO KOLAREVIC
 3.1. Fish Sculpture (1992), Vila Olimpica, Barcelona, Spain, architect Frank Gehry.
The digital age has radically reconfigured the relationship between conception and produc- tion, creating a direct link between what can be conceived and what can be constructed. Building projects today are not only born out digitally, but they are also realized digitally through “file-to-factory” processes of computer numerically controlled (CNC) fabrication technologies.
It was the complexity of “blobby” forms that drew architects, out of sheer necessity, back into being closely involved with the production of buildings. The continuous, highly curvilinear surfaces, which feature prominently in contemporary architecture, brought to the fore the question of how to work out the spatial and tectonic ramifications of such com- plex forms. It was the challenge of constructability that brought into question the credibility of spatial complexities introduced by the new “digital” avant-garde. But as constructability becomes a direct function of computability, the question is no longer whether a particular form is buildable, but what new instruments of practice are needed to take advantage of the opportunities opened up by the digital modes of production.
 3.2. Digitizing of a three-dimensional model in Frank Gehry’s office.

Digital production 47
One of the first projects to be developed and realized digitally was Frank Gehry’s design for the large Fish Sculpture at the entrance to a retail complex called Vila Olimpica in Barcelona, Spain (1992, figure 3.1). The project’s financial and scheduling constraints led Gehry’s partner Jim Glymph to search for a digital design and manufacturing software environment that would make the complex geometry of the project not only describable, but also producible, using digital means in order to ensure a high degree of precision in fabrication and assembly. The solution was found in the three-dimensional modeling and manufacturing program developed for the French aerospace industry (Dassault Systems), called CATIA, an acronym that stands for Computer Aided Three-dimensional Interactive Application. Thus, the software made for the design and manufacture of airplanes was used to develop and construct a built structure. Three-dimensional digital models were used in the design development, for structural analysis, and as a source of construction informa- tion, in a radical departure from the normative practices of the profession. The bellwether of digital revolution for architecture had finally arrived.
THREE-DIMENSIONAL SCANNING: FROM PHYSICAL TO DIGITAL
For some designers, such as Frank Gehry, the direct tactility of a physical model is a much preferred way of designing than a “flat” digital manipulation of surfaces on a computer screen. In Gehry’s case, the digital technologies are not used as a medium of conception but as a medium of translation in a process that takes as its input the geometry of the physi- cal model (figure 3.2) and produces as its output the digitally-encoded control information which is used to drive various fabrication machines (figures 3.3a-c). As it will be demon- strated in this chapter, digital representations of geometry can be used in ways the original physical models cannot.
The process of translation from the physical to the digital realm is the inverse of com- puter-aided manufacturing. From a physical model a digital representation of its geometry can be created using various three-dimensional scanning techniques in a process often referred to as “reverse engineering.” A pattern of points, called the “point cloud” (figure 3.4a), is created from the physical model through scanning, and is then interpreted by the conversion software to produce a close approximation of the model’s geometry. Typi- cally, patterns of scanned points (figure 3.4b) are used to generate profile NURBS (Non- Uniform Rational B-Splines) curves (figure 3.4c), which are then used to generate lofted
3.3a–c. The translation process in Gehry’s office: (a) digitized points; (b) digital surface reconstruction; and (c) digitally fabricated model.

48 Architecture in the Digital Age
     3.4a–e. The reverse engineering process: (a) point cloud from three-dimensional scanning; (b) and (c) cross-sectional curve generation; (d) surface lofting, and (e) comparison with
the point cloud.
NURBS surfaces (figure 3.4d). The resulting surfaces can be compared to the scanned point cloud for an analysis of deviations from the original physical model (figure 3.4e).
A common method for three-dimensional scanning involves the use of a digitizing posi- tion probe to trace surface features of the physical model. This procedure can be done manually using three-dimensional digitizing arms (figure 3.5) or automatically using a Coordinate Measuring Machine (CMM), which has a digitizing position sensor that is mechanically kept in contact with the surface of the scanned object.
An alternative is to use non-contact scanning methods, which require more expensive scanning devices, but are faster, more accurate, less labor intensive, and often more effec- tive when scanning small-scale objects. These devices commonly use laser light to illu- minate the surface of a scanned object (figure 3.6) in a step-by-step fashion, producing patterns of bright dots or lines, which are captured by digital cameras (two are often used). The recorded images are processed using optical recognition techniques to construct the three-dimensional geometric model of the scanned object, which can then be exported in a desired data format for use in digital analysis or modeling applications.
Three-dimensional scanning techniques can be used to digitally capture not only the physical models, but also existing or as-built conditions, or even entire landscapes. Laser scanning technologies, based on different measurement techniques, are commonly used in surveying on construction sites worldwide (figure 3.7). In each of the different devices available on the market, a laser beam is emitted by the scanner and the reflected beam is captured, and its properties analyzed to calculate the distances to the measured object. Four pieces of information are captured for each individual point measurement: X, Y and Z coordinates plus the intensity of the reflected beam, which can be used to assign different light intensities or even colors to the point cloud.
Laser scanning technologies can create very accurate three-dimensional models of existing objects.1 Today, they are used increasingly on construction sites in place of con- ventional measuring devices to quickly measure distances and to precisely determine loca- tions for the installation of various building components. It is conceivable that the laser scanning will also be used to continuously scan the building’s structure as it is erected and to immediately detect deviations from the geometry of the digital model. The “point cloud” is already in the builder’s vocabulary, and the laser scanning has already rendered the tape measure obsolete on numerous construction sites.

Digital production 49 DIGITAL FABRICATION: FROM DIGITAL TO PHYSICAL
The long tradition of Euclidean geometry in building brought about drafting instruments, such as the straightedge and the compass, needed to draw straight lines and circles on paper, and the corresponding extrusion and rolling machinery to produce straight lines and circles in material. The consequence was, as William Mitchell observed, that architects drew what they could build, and built what they could draw.2 This reciprocity between the means of representation and production has not disappeared entirely in the digital age. Knowing the production capabilities and availability of particular digitally-driven
3.5. The Microscribe three-dimensional digitizer.
3.6. Three-dimensional laser scanner.

50 Architecture in the Digital Age
 3.7. Three-dimensional laser scanner for site surveying.
3.8a–b. Nationale-Nederlanden Building (1996), Prague, Czech Republic, architect Frank Gehry: irregularly-shaped glass panels were cut using digitally-driven cutting machines.
fabrication equipment enables architects to design specifically for the capabilities of those machines. The consequence is that architects are becoming much more directly involved in the fabrication processes, as they create the information that is translated by fabricators directly into the control data that drives the digital fabrication equipment. For instance, the irregularly-shaped glass panels on Frank Gehry’s Nationale-Nederlanden Building in Prague, Czech Republic, (1996, figures 3.8a-b), were cut using digitally-driven cutting machines from the geometric information extracted directly from the digital model, as was also the case with more than 21,000 differently shaped metal shingles for the exterior of the Experience Music Project (EMP) in Seattle, also designed by Frank Gehry (2000, figures 3.9a–b). A growing number of successfully completed projects, which vary considerably in size and budgets, demonstrate that digital fabrication can offer productive opportunities within schedule and budget frameworks that need not be extraordinary.

Digital production 51
The new digitally-enabled processes of production imply that the constructability in building design becomes a direct function of computability. The fact that complex geom- etries are described precisely as NURBS curves and surfaces, and, thus, computationally possible, also means that their construction is attainable by means of CNC fabrication processes. Production processes based on cutting, subtractive, additive and formative fab- rication, which are described in more detail in this chapter, offer rich opportunities for the tectonic exploration of new geometries.3
3.9a–b. Experience Music Project (EMP) (2000), Seattle, USA, architect Frank Gehry: 21,000 differently shaped metal shingles for the exterior were cut digitally.
3.10. Plasma-arc CNC cutting of steel supports for masonry walls in Frank Gehry’s Zollhof Towers (2000) in Düsseldorf, Germany.
3.11. A water-jet nozzle.

52 Architecture in the Digital Age
TWO-DIMENSIONAL FABRICATION
CNC cutting, or two-dimensional fabrication, is the most commonly used fabrication tech- nique. Various cutting technologies, such as plasma-arc, laser-beam and water-jet, involve two-axis motion of the sheet material relative to the cutting head, and are implemented as a moving cutting head, a moving bed or a combination of the two. In plasma-arc cutting, an electric arc is passed through a compressed gas jet in the cutting nozzle, heating the gas into plasma with a very high temperature (25,000°F), which converts back into gas as it passes the heat to the cutting zone (figure 3.10). In water-jets, as their name suggests, a jet of highly pressurized water is mixed with solid abrasive particles and is forced through a tiny nozzle in a highly focused stream (figure 3.11), causing the rapid erosion of the material in its path and producing very clean and accurate cuts (figure 3.12). Laser-cutters use a high- intensity focused beam of infrared light in combination with a jet of highly pressurized gas (carbon dioxide) to melt or burn the material that is being cut. There are, however, large differences between these technologies in the kinds of materials or maximum thicknesses that could be cut. While laser-cutters can only cut materials that can absorb light energy, water-jets can cut almost any material. Laser-cutters can cut material up to 5/8 inches (16 mm) cost-effectively, while water-jets can cut much thicker materials, for example, up to 15 inches (38 cm) of thick titanium.
3.12. The “Bubble” (1999), BMW Pavilion, Frankfurt, Germany, architects Bernhard Franken and ABB Architekten: the aluminum frame is cut directly from digital data using
CNC water-jet technology.
SUBTRACTIVE FABRICATION
Subtractive fabrication involves the removal of a specified volume of material from solids (hence the name) using electro-, chemically- or mechanically-reductive (multi-axis mill- ing) processes. The milling can be axially, surface or volume constrained. In axially con- strained devices, such as lathes, the piece of material that is milled has one axis of rotational motion, and the milling head has two axes of translational motion. Surface constrained milling machines are conceptually identical to the cutting machines discussed previously.

Digital production 53
In two-axis milling routers, the rotating drill-bit is moved along X and Y axes to remove two-dimensional patterns of material.
The milling of three-dimensional solids is a straightforward extension of two-dimen- sional cutting. By adding the ability to raise or lower the drill-bit, i.e. to move it along the third, Z axis, the three-axial milling machines could remove material volumetrically. Because of the inherent limitations of three-axial milling, the range of forms that could be produced with these machines is limited. For example, undercuts as shown in figure 3.13 cannot be accomplished with three-axis milling devices. For such shapes, a four- or five- axis machines are used. In four-axis systems, an additional axis of rotation is provided, either for the cutting head or the cutting bed that holds the piece (the A-axis), and in five- axis systems one more axis of rotation (the B-axis) is added (figure 3.14). In this fashion, the cutting head can perform the “undercuts” and can substantially increase the range of forms that can be produced using milling.
The drill bits inserted into the cutting heads can be of different sizes, i.e. diameters. Large bits are used for the coarse removal of material, and smaller bits for finishing. The milling itself can be done at different rotational speeds, depending on the hardness or other properties of the material that is milled.
3.15. A simple CNC program.
O0001 N005 G54 N010 G00 N015 G43 N020 G01 N025 G00 N030 X2. N035 G01 N040 G00 N045 G91 N050 M30
G90 S400 M03 X1. Y1.
H01 Z.1 M08 Z-1.25 F3.5 Z.1
Z-1.25 Z.1 M09 G28 Z0
 3.13. Undercuts cannot be milled with three-axis milling machines.
In CNC milling, a dedicated computer system performs the basic controlling functions over the movement of a machine tool using a set of coded instructions. The geometry

54 Architecture in the Digital Age
is imported into so-called post-processing software that generates the CNC instructions which are transmitted to the milling machine. The CNC instructions control the motion, the feedrate, operation of the spindle drive, coolant supply, tool changes, and other operational parameters. As milling of shapes can be accomplished in a variety of ways, generating an appropriate “tool path” is not a trivial task, especially for four- or five-axis machines, which is often executed by skilled operators. The tool path itself is expressed as a CNC program, which is nothing more than a sequence of coded instructions for the machine to execute (figure 3.15). The CNC programs are made of commands that consist of words, each of which has a letter address and an associated numerical value. The so-called preparatory functions that, for example, control the motion of the machining tool, are often designated with a “G” letter. In a typical CNC program, the majority of “words” are these preparatory functions. Because of this, the CNC code is often referred to as “G-code” among CAM (computer-aided manufacturing) operators.
The CNC multi-axis milling is one of the oldest digital fabrication technologies. Early experiments in using CNC milling machines to produce architectural models were carried out in early 1970s in the United Kingdom. Large architectural firms in the United States,
3.14. Five-axis milling system.
such as Skidmore, Owings and Merrill’s (SOM) office in Chicago, have used CNC milling machines and laser cutters extensively in the production of architectural models and studies of construction assemblies. Automated milling machines were used in the late 1980s and in the 1990s to produce construction components,4 such as stones for New York’s Cathe- dral of Saint John the Divine and columns for the Sagrada Familia Church in Barcelona. Frank Gehry’s project for the Walt Disney Concert Hall in Los Angeles represents the first comprehensive use of CAD/CAM to produce architectural stonework (before that project was redesigned with a metal skin). For the initial 1:1 scale model, the stone panels with double-curved geometry were CNC milled in Italy and then shipped to Los Angeles, where they were positioned and fixed in place on steel frames. Gehry’s office used this same fab- rication technique for the stone cladding in the Bilbao project
The CNC milling has recently been applied in new ways in the building industry—to produce the formwork (molds) for the off-site and on-site casting of concrete elements with double-curved geometry, as was done in one of Gehry’s office buildings in Düssel-

Digital production 55
dorf, Germany, in 2000, and for the production of the laminated glass panels with complex curvilinear surfaces, as in Gehry’s Condé Nast Cafeteria project in New York (2000) and Bernard Franken’s “Bubble” BMW pavilion (1999, figures 3.16a-c).
3.16a–c. The double-curved acrylic glass panels for Bernhard Franken’s produced using CNC-“Bubble” BMW pavilion (1999) were milled molds.
3.17a–f. The reinforced concrete panels for Gehry’s Zollhof Towers (2000) in Düsseldorf, Germany, were precast in CNC-milled Styrofoam molds.

56 Architecture in the Digital Age
In Gehry’s project in Düsseldorf (Zollhof Towers), the undulating forms of the load-bearing external wall panels, made of reinforced concrete, were produced using blocks of light- weight polystyrene (Styrofoam), which were shaped in CATIA and were CNC milled (fig- ures 3.17a-f) to produce 355 different curved molds that became the forms for the casting of the concrete.5
ADDITIVE FABRICATION
Additive fabrication involves incremental forming by adding material in a layer-by-layer fashion, in a process which is the converse of milling. It is often referred to as layered manufacturing, solid freeform fabrication, rapid prototyping, or desktop manufacturing. All additive fabrication technologies share the same principle in that the digital (solid) model is sliced into two-dimensional layers (figure 3.18). The information of each layer is then transferred to the processing head of the manufacturing machine and the physical product is generated incrementally in a layer-by-layer fashion.
Since the first commercial system based on stereolithography was introduced by 3D Systems in 1988 (figure 3.19), a number of competing technologies have emerged on the market, utilizing a variety of materials and a range of curing processes based on light, heat, or chemicals.6 Stereolithography (SLA) is based on liquid polymers that solidify when exposed to laser light. A laser beam traces a cross-section of the model in a vat of light- sensitive liquid polymer. A thin solid layer is produced in the areas hit by the laser light. The solidified part, which sits on a submerged platform, is then lowered by a small incre- ment into the vat, and the laser beam then traces the next layer, i.e. the cross-section of the digital model. This process is repeated until the entire model is completed. At the end of the process, the platform with the solidified model is raised from the vat, and the model is then cured to remove extraneous liquid and to give it greater rigidity.
In Selective Laser Sintering (SLS), the laser beam melts layer by layer of metal powder to create solid objects. In 3D Printing (3DP), layers of ceramic powder are glued to form objects (figure 3.20). Sheets of material (paper or plastic), either precut or on a roll, are glued (laminated) together and laser cut in the Laminated Object Manufacture (LOM) pro- cess. In Fused Deposition Modeling (FDM), each cross-section is produced by melting a plastic filament that solidifies upon cooling. Multi-jet manufacture (MJM) uses a modified printing head to deposit melted thermoplastic wax material in very thin layers, one layer at a time, to create three-dimensional solids (figure 3.21).
3.18. Layered manufacturing.

3.19. The SLA 250 stereolithography system by 3D Systems.
3.20. ZCorp’s Z406 3D printer.
3.21. Thermojet printer by 3D Systems.
Because of the limited size of the objects that could be produced, costly equipment and lengthy production times, the additive fabrication processes have a rather limited applica- tion in building design and production. In design, they are used mainly for the fabrication of (massing) models with complex, curvilinear geometries (figure 3.22). In construction, they are used to produce components in series, such as steel elements in light truss struc- tures, by creating patterns that are then used in investment casting (figures 3.23a–b).
Recently, however, several experimental techniques based on sprayed concrete were in- troduced to manufacture large-scale building components directly from digital data. A fairly recent additive technology called contour crafting, invented and patented by Behrokh
Digital production 57

58 Architecture in the Digital Age
Khoshnevis from the University of Southern California, allows fairly quick layered fab- rication of highly finished buildings.7 Contour crafting is a hybrid automated fabrication method that combines extrusion for forming the surface shell of an object and a filling pro- cess based on pouring or injection to build the object’s core. Computer-controlled trowels, the flat blades used for centuries to shape fluid materials such as clay or plaster, are used to shape the outside edges (rims) of each cross-section on a given layer, which are then filled with concrete or some other filler material. Since material deposition is computer- controlled, accurate amounts of different materials can be added precisely in desired loca- tions, and other elements, such as various sensors, floor and wall heaters, can be built into the structure in a fully automated fashion.
3.22. The stereolithography model of the House Prototype in Long Island project by Greg Lynn.
3.23a–b. TriPyramid, a fabricator in New York, used rapid prototyping to manufacture truss elements for Polshek’s Rose Center for Earth and Sciences (2000) in New York.
FORMATIVE FABRICATION
In formative fabrication mechanical forces, restricting forms, heat or steam are applied to a material so as to form it into the desired shape through reshaping or deformation, which can be axially or surface constrained. For example, the reshaped material may be deformed permanently by such processes as stressing metal past the elastic limit, heating metal and then bending it while it is in a softened state, steam-bending boards, etc. Double-curved, compound surfaces can be approximated by arrays of height-adjustable,

Digital production 59
numerically- controlled pins, which could be used for the production of molded glass and plastic sheets and for curved stamped metal. Plane curves can be fabricated by the numer- ically-controlled bending of thin rods, tubes or strips of elastic material, such as steel or wood, as was done in several exhibition pavilions designed by Bernhard Franken for BMW (figures 3.24a–b).
ASSEMBLY
After the components are digitally fabricated, their assembly on site can be augmented with digital technology. Digital three-dimensional models can be used to precisely deter- mine the location of each component, move each component to its location and, finally, fix each component in its proper place. Traditionally, builders took dimensions and coordi- nates from paper drawings and used tape measures, plumb-bobs and other devices to locate the building components on site. New digitally-driven technologies, such as electronic surveying and laser positioning (figure 3.25), are increasingly being used on construction sites around the world to precisely determine the location of building components. For example, as described by Annette LeCuyer, Frank Gehry’s Guggenheim Museum in Bilbao “was built without any tape measures. During fabrication, each structural component was bar coded and marked with the nodes of intersection with adjacent layers of structure. On site bar codes were swiped to reveal the coordinates of each piece in the CATIA model. Laser surveying equipment linked to CATIA enabled each piece to be precisely placed in its position as defined by the computer model.”8 Similar processes were used on Gehry’s EMP project in Seattle (figures 3.26a-c).9 As LeCuyer notes, these processes are common practice in the aerospace industry, but relatively new to building.10
The geometric data extracted from the digital three-dimensional model can be used to control construction robots that can automatically carry out a variety of tasks on construc- tion sites. In Japan, a number of robotic devices for the moving and fixing of components were developed, such as Shimizu’s Mighty Jack for heavy steel beam positioning, Kajima’s Reinforcing Bar Arranging Robot, Obayashi-Gumi’s Concrete Placer for pouring
3.24a–b. The CNC bending of the aluminum profiles for the “Brandscape” BMW Pavilion at the 2000 Auto Show in Geneva, Switzerland, architects Bernhard Franken and ABB
Architekten.

60 Architecture in the Digital Age
concrete into forms, Takenaka’s Self-Climbing Inspection Machine, Taisei’s Pillar Coating
Robot for painting, and Shimizu’s Insulation Spray Robot (figure 3.27).
 3.25. Trimble’s 5600 Series Total Station advanced surveying system.
It is conceivable that in the not so distant future architects will directly transmit the design information to a construction machine that will automatically assemble a complete build- ing. The SMART system, which stands for Shimizu Manufacturing system by Advanced Robotics Technology, is the world’s first digitally-driven, automated construction system that was actually applied to a full-scale building project. In the 20-storey Juroku Bank Building in Nagoya, Japan, Shimizu’s SMART construction machine automatically erected and welded the structural steel frame and placed and installed the concrete floor panels and exterior and interior walls. The SMART system showed that it is possible to fully automate the identification, transport and installation of building components using a computerized information management system.
These experiments by Japanese construction companies are System (GPS) harbingers of the inevitable digital evolution in the building industry. A radical reconceptualization of building practices is technologically possible today; the realities of economic and social constraints in the building industry simply mean that the processes of change will be evo- lutionary rather than revolutionary, and will most likely occur over several decades.
 3.26a–c. Global Positioning technology was used on Frank Gehry’s Experience Music Project in Seattle (EMP) (2000) to verify the location of components.

SURFACE STRATEGIES
Architects today digitally create and manipulate NURBS surfaces, producing building skins that result not only in new expressive and aesthetic qualities, but also in new tectonic and geometric complexities. It is the surface and not necessarily the structure that preoc- cupies the work of the digital avant-garde in its exploration of new formal territories. The exterior surface of a building—its skin—becomes necessarily emphasized due to the logics of formal conception inherent in the NURBS-based software, as discussed in the previous chapter.
The explorations in constructability of geometrically complex envelopes in the projects of the digital avant-garde have led to a rethinking of surface tectonics. The building enve- lope is increasingly being explored for its potential to reunify the skin and the structure in opposition to the binary logics of the Modernist tectonic thinking. The structure becomes embedded or subsumed into the skin, as in semi-monocoque and monocoque structures, in which the skin absorbs all or most of the stresses. The principal idea is to conflate the structure and the skin into one element, thus creating self-supporting forms that require no armature. That, in turn, prompted a search for “new” materials, such as high-tempera- ture foams, rubbers, plastics and composites, which were, until recently, rarely used in the building industry. As observed by Joseph Giovannini, “the idea of a structural skin not only implies a new material, but also geometries, such as curves and folds that would enable
3.27. Shimizu’s Insulation Spray Robot.
the continuous skin to act structurally, obviating an independent static system: The skin alone does the heavy lifting.”11 Thus, an interesting reciprocal relationship is established between the new geometries and new materialities: new geometries opened up a quest for new materials and vice versa. Kolatan and Mac Donald’s Raybould House addition (2003) project in Connecticut (figure 3.28) nicely illustrates that reciprocity—the building is to
Digital production 61

62 Architecture in the Digital Age
be made of polyurethane foam sprayed over an egg-crate plywood armature that should be CNC cut (figure 3.29); the resulting monocoque structure is structurally self-sufficient without the egg-crate, which should remain captured within the monocoque form.
The fusion of the structure and the skin in monocoque and semi-monocoque envelopes is already having a considerable impact on the design of structures and cladding in particular. The new thin, layered building envelopes are made of panels that provide not only enclo- sure and structural support, but also contain other systems typically placed into ceilings or floors. These developments in cladding are driven in part by technologies and concepts from other industries, such as the “stressed skins” long used in automotive, aerospace, and shipbuilding production. For example, in airplanes, the cage-like structure called airframe (figure 3.30), made from aluminum alloys, is covered by aluminum panels to form a semi- monocoque envelope in which the structure and skin are separate tectonic elements but act in unison to absorb stresses.
The “blobby” shell of the NatWest Media Centre (1999) building (figure 1.21) at Lord’s Cricket Ground in London was designed by Future Systems and built as an aluminum semi- monocoque structure in a boatyard. Aluminum was the material of choice because it does not corrode and it can be formed to make a waterproof skin; the skin is also structural in this case, thus making a separate framing structure or cladding unnecessary. The shell was manufactured from CNC cut, 6 and 12 mm thick aluminum plates and was pre-assembled in a boatyard (figure 1.22). It was then divided into 26, 3 m wide sections (figure 3.31) and transported to the site, where it was reassembled on two giant concrete pillars. Aluminum semi-monocoque structures were also used by Jakob and MacFarlane in the Georges Res- taurant (2000), at Centre Pompidou, Paris, France (figures 3.32 and 33a-b). The structural elements were digitally cut out of 10 mm thick aluminum; the skin was made from 4 mm thick sheets of aluminum that were bent into doubly-curved shapes using traditional boat building methods.
The implications of these new structural skins are significant, as noted by Joseph Giovannini, because they signify a radical departure from Modernism’s ideals:
3.28. Kolatan and Mac Donald’s Raybould House addition (2003) in Connecticut.

3.29 Raybould House: eggcrate armature for the polyurethane shell.
3.30. In airplanes the structure and the skin act in unison to absorb stresses.
“In some ways the search for a material and form that unifies structure and skin is a coun- terrevolution to Le Corbusier’s Domino House, in which the master separated structure from skin. The new conflation is a return to the bearing wall, but one with freedoms that Corb never imagined possible. Architects could build many more exciting buildings on the Statue of Liberty paradigm, but complex surfaces with integrated structures promise a quantum leap of engineering elegance and intellectual satisfaction.”12
Digital production 63

64 Architecture in the Digital Age
 3.31. NatWest Media Centre (1999), Lord’s Cricket Ground, London, UK, architect Future Systems: the semi-monocoque aluminum shell was made from 26 segments.
3.32. Restaurant Georges (2000), Centre Pompidou, Paris, France, architects Jakob + Mac- Farlane.
Other less radical strategies involve offsetting the structure from the skin into its own layer (figure 3.34), which is the approach Frank Gehry has applied to most of his recent projects. The process of working from the skin to the structure is a common practice in automotive and aerospace industries, where the spatial envelope is fixed early on. Such an approach is a relative novelty in architecture, a clear departure from the “primacy of structure” logics of the Modernism. Another approach is a distinct separation of the skin and the structure, where the spatial juxtaposition can produce potent visual interplays. Gustave Eiffel’s struc- tural frame for Auguste Bartholdi’s contoured skin for the Statue of Liberty (figure 3.35)

3.33a–b. Restaurant Georges: model of the monocoque shell for the “bar” volume.
3.34. Assembly of the structural frame for the Disney Concert Hall (2003), Los Angeles, architect Frank Gehry.
provides a telling precedent that demonstrates clearly the possibilities that open up by such an approach to surface tectonics. There is also a conventional approach in which the sinuous skin is attached to a conventionally-conceived structural grid, which, if carefully applied, can produced interesting results. Each of these approaches to skin and structure is perfectly valid and each has different repercussions for the development of the project relative to its overall cost and desired spatial qualities.
The strategies for articulating the tectonics of NURBS-based envelopes are driven by their geometric complexity, possibilities and resistances offered by the intended material composition, and structural considerations, all of which could have significant implica- tions for the overall cost of the project These “rules of constructability” often demand rationalizations in the geometry of tectonic components, which could be ordered according
Digital production 65

66 Architecture in the Digital Age
to their cost (from lower to higher) into straight or flat, radially bent, doubly curved, and highly shaped (or distorted, often by stretching). The digital technologies enable architects to attain exact control over the budget by precisely controlling the geometry.
3.35. Statue of Liberty (1886), New York, architects Gustave Eiffel and Auguste Bartholdi: folds, armature and bracing.
3.36a–b. Structural frames in Frank Gehry’s Experience Music Project (2000) in Seattle were produced by contouring.

3.37. Structural framework for Bernhard Franken’s “Bubble” BMW Pavilion produced by bi-directional contouring.
PRODUCTION STRATEGIES
The production strategies used for two-dimensional fabrication often include contouring, triangulation (or polygonal tessellation), use of ruled, developable surfaces, and unfolding. They all involve the extraction of two-dimensional, planar components from geometrically complex surfaces or solids comprising the building’s form. The challenge in the two- dimensional interpretation, of course, is to choose an appropriate geometric approximation that will preserve the essential qualities of the initial three-dimensional form. Which of the production strategies is used depends on what is being defined tectonically: structure, envelope, a combination of the two, etc.
In contouring, a sequence of planar sections, often parallel to each other and placed at regular intervals, are produced automatically by modeling software from a given form and can be used directly to articulate structural components of the building, as was the case in a number of recently completed projects (figures 3.36a-b and 3.37). Contouring is conceptu- ally identical to a process called lofting in shipbuilding, in which the shape of a ship’s hull is defined by a sequence of planar lateral cross-sections that become “ribs” mounted on a “spine” that runs lengthwise (figure 3.38).
3.38. Structural framework for a ship’s hull.
Digital production 67

68 Architecture in the Digital Age
The wireframe cross-sections, produced by contouring, can be further manipulated to cre- ate a complete abstraction of the building’s structural framework, which could then be processed by the structural analysis software to generate the precise definition of all struc- tural members. In Gehry’s Bilbao project, the contractor used a software program from Germany called Bocad to automatically generate a comprehensive digital model of the structural steel, including the brace-framed and secondary steel structures for the museum (figure 3.39).13 More importantly, that same program was used to automatically produce the fabrication drawings, or CNC data, to precisely cut and pre-assemble the various compo- nents.14 Similar structural steel detailing software (and fabrication) were used on the Walt Disney Concert Hall and other recent projects by Gehry’s office.
3.39. Steel detailing software was used to generate a comprehensive digital model of the steel structure for Gehry’s Guggenheim Museum (1997) in bilbao, Spain.
A potentially interesting contouring technique involves the extraction of the isoparametric curves (“isoparms”) used to aid in visualizing NURBS surfaces through contouring in the “U” and “V” direction, as discussed in the previous chapter. For example, the tubu- lar members for the “Brandscape” BMW Pavilion (figure 3.40), designed by Bernhard Franken in association with ABB Architekten for the 2000 Autoshow in Geneva, featured CNC-formed, doubly-curved geometry extracted as isoparms from the complex NURBS surface (figure 3.41). Sometimes, due to budgetary or other production-related constraints, the complex geometry of the NURBS curves can be approximated with circular, radial geometry, which can be inexpensively manufactured using rolling machines (figure 3.42). In this approach, the complexity lies in the precise connection among different pieces and the required temporary structures for assembly. This approximation, using radial geometry, was also used by Franken and his team for the production of structural members in the “Brandscape” BMW Pavilion.

3.40. Assembly of the “Brandscape” BMW Pavilion at the 2000 Auto Show in Geneva, Switzerland, architects Bernhard Franken and ABB Architekten.
While isoparms can lead to a “true” tectonic expression of the three-dimensional form, they pose non-trivial production challenges, as fabrication of doubly-curved structural members requires expensive equipment and temporary egg-crate (created through planar contour- ing) or other structures for the precise positioning in the construction assembly. The use of NURBS isoparms may also lead to suboptimal structural solutions; instead, isoparametric curves produced by structural analysis could be used for defining the geometry of structural components.
3.41. “Brandscape”: the frame members’ geometry was derived from the NURBS surface isoparms.
Digital production 69

70 Architecture in the Digital Age
 3.42. “Brandscape”: the geometry of the perimeter tubes was rationalized into tangent circular arcs.
Complex, curvilinear surface envelopes are often produced by either triangulation (figure 3.43) or some other planar tessellation, or by the conversion of double-curved into ruled surfaces, which are generated by linear interpolation between two curves (figure 3.44). Triangulated or ruled surfaces are then unfolded into planar strips (figures 3.45 and 3.46), which are laid out in some optimal fashion as two-dimensional shapes on a sheet (in a process called nesting), which is then used to cut the corresponding pieces of the sheet material using one of the CNC cutting technologies.
3.43. Triangulation of a doubly-curved surface.
3.44. Ruled surface

72 Architecture in the Digital Age
One of the best know examples of polygonal tessellation are the roof forms of the Syd- ney Opera House (1973) designed by Jørn Utzon. The initial freeform shapes sketched by Utzon were first approximated by surface segments extracted from spheres of varying radii, and were then subdivided into flat patches (figure 3.47). Triangulation is the most commonly applied form of planar tessellation. It was used, for example, in the glass roof of the DG Bank (2001) building (figure 3.48) that Frank Gehry designed at Parizer Platz in Berlin, Germany. The triangulated space frame was constructed from solid stainless steel rods that meet at different angles at six-legged star-shaped nodal connectors, each of which was unique and was CNC cut from 70 mm thick stainless steel plate. The frame was infilled by approximately 1,500 triangular glazing panels, which were also CNC cut. A similar production strategy was used in the glass roof of the Great Court in the British Museum in London, designed by Foster and Partners (figure 3.49). The irregularly-shaped and deformed “sliced” torus form of the roof was rationalized as a triangulated frame net- work consisting of 4,878 hollow rods and 1,566 connector nodes, all of them different from each other and all of them CNC cut. The frame was then filled with 3,312 glass panes, each of which was unique, due to the irregular geometry of the roof’s perimeter.
3.48. Triangulated complex surfaces in Frank Gehry’s DG Bank (2000) building in Parizer Platz, Berlin, Germany.
In some of their recent projects, Foster’s office has created designs with complex geom- etries that are based on parameterized, concatenated torus patches that smoothly transi- tion to each other. As with complex curves, rationalizations based on the radial geometry of spheres, cones, cylinders or tori, are often deployed to approximate complexly-curved surfaces. The roof structure of the Music Centre (2003) in Gateshead, UK, designed by Foster’s office, consists of a series of torus patches, which curve in both directions and are mutually dependent (figure 3.50). Each of the patches is subdivided into bands of identical four-sided flat panels, whose size can be parametrically varied to match the specific pro- duction and construction constraints.

3.49. The triangulated toroidal surface of the British Museum Great Court (2000), London, UK, architect Foster and Partners.
Other multi-sided tessellation patterns are also possible. More sophisticated modeling pro- grams often provide a rich repertoire of tessellation options, allowing designers to choose not only the geometry of the patches but also their minimum and maximum size. By vary- ing the tessellation parameters, designers could interactively explore various approxima- tion strategies to match various cost and production scenarios. Other surface subdivision algorithms can be used to divide a complex surface into a collection of patches, which are not necessarily flat. Sometimes, custom surface subdivision procedures are developed, as was done by Dennis Shelden in Gehry’s office for the definition of the geometry of some 21,000 different metal shingles on the EMP project in Seattle (figure 3.51).
Another method of “rationalizing” double-curved surfaces is to convert them into “rule- developable” surfaces. Ruled surfaces are generated by linear interpolation between two
3.50. The toroidal geometry of Foster and Partner’s Music Centre (2003), Gateshead, UK.
Digital production 73

74 Architecture in the Digital Age
curves in space, i.e. by connecting pairs of curves with straight, “ruling” lines that are placed at regular intervals (figure 3.44). A wide variety of surfaces can be generated in this fashion. The simplest ones are cones and cylinders; the more interesting forms from an architectural point of view are saddle-shaped hyperbolic paraboloids (figure 3.52) and hyperboloids (figure 3.53), a common form for the cooling towers of nuclear power stations.
The ruled surfaces are fairly easy to construct using conventional construction tech- niques. Relatively simple formwork is required for concrete structures. Stonemasons, for example, have used templates to cut complex ruled surface forms out of stones for centu- ries. For some architects, such as the well-known Uruguayan architect Eladio Dieste, the ruled surfaces were a preferred means of architectural expression in a number of his build- ing designs (figure 3.54).
3.51. Surface subdivision of the exterior envelope in EMP (2000), Seattle, architect Gehry Partners.
3.52. Ruled surface: hyperbolic paraboloid.
   3.53. Ruled surface: hyperboloid.

Digital production 75
Ruled surfaces are used extensively in contemporary architectural practice because they can be “developed,” i.e. unfolded into flat shapes in modeling software (figure 3.46), and digitally fabricated out of flat sheets. “Developable” surfaces can be formed by rolling a flat sheet of material without deformation, i.e. with no stretching, tearing or creases. They curve only in one isoparametric direction, i.e. they are linear in the other direction (figure 3.55a–c), unlike the doubly-curved NURBS surfaces.
Frank Gehry’s office relies extensively on the use of ruled, developable surfaces to ensure the buildability of his sinuous designs within reasonable schedule and budgetary constraints (figures 3.56a– b). Gehry physically models his conceptual designs by shaping into desired forms the “developable” strips of paper or metal. These forms are digitized and the resulting surfaces are then analyzed in CATIA software and converted into digitally developable surfaces.
3.54. Atlantida Church (1958), Uruguay, architect Eladio Dieste.
3.55a–c. Use of ruled surfaces in the Water Pavilion (1998), the Netherlands, architect Lars Spuybroek/NOX Architects.

76 Architecture in the Digital Age
 3.56a–b. Use of ruled surfaces in the Walt Disney Concert Hall (2003), Los Angeles, archi- tect Gehry Partners.
3.57. The doubly curved steel plates for the conference chamber of the DG Bank (2000), Berlin, Germany, architect Gehry Partners.
The fabrication technologies allow the production of non-developable doubly-curved sur- faces, albeit at a higher cost. As discussed earlier, doubly-curved concrete elements can be formed in CNC-milled Styrofoam molds, as was done for the Zollhof Towers (2000) designed by Gehry in Düsseldorf, Germany (figures 3.17a–f). Glass panels with complex curvature can be produced in a similar fashion, by heating the flat sheets of glass over

Digital production 77
CNC-milled molds in high-temperature ovens (figures 3.16a–d). CNC-driven pin-beds can be used to shape metal panels into doubly-curved forms. For example, the large stain- less steel plates (2 m×4 m) for the conference chamber of the DG Bank (2000) building, designed by Gehry at the Parizer Platz in Berlin, were shaped by boatbuilders to produce its complex doubly-curved form (figure 3.57).
Whether a particular section of the building’s envelope is produced as a developable or doubly-curved surface can be determined by applying the Gaussian analysis to the surface model. The Gaussian analysis evaluates the degree of curvature in complexly-shaped ele- ments and produces a colored image that indicates, through various colors, the extent of the surface curvature—a blue color indicates areas of no or minimum curvature, red is applied to maximum values, and green is used for areas with a median curvature (figure 3.58). Developable surfaces, for example, have zero Gaussian curvature at every point on the surface, because they are linear in one direction (figure 3.59).
3.58. Gaussian analysis of a doubly-curved surface.
3.59. Gaussian analysis of a developable surface.
In designing the Guggenheim Museum in Bilbao, Gehry’s office used the Gaussian analysis to determine the areas of excessive curvature (figure 3.60), as there are limits as to how much the sheets of metal could be bent in two directions—the same technique was used on other projects by Gehry. For example, Gaussian analysis was used in the EMP in Seattle to determine which of the apparently double-curved surface patches can be converted into developable ones (figure 3.61) and which ones need to be complexly shaped, thus provid- ing Gehry’s office with an important ability to determine and control the overall cost of manufacturing elements of a particularly complex envelope.

78 Architecture in the Digital Age
 3.60. Guggenheim Museum: Gaussian analysis.
3.61. Experience Music Project Gaussian analysis.
NEW MATERIALITY
New forms of architectural expression and advances in material science have led to a renewed interest among architects in materials, their properties and their capacity to produce desired aesthetic and spatial effects. As was often the case in the past, a formal departure from the basic, normative geometries would often coincide with the development of new materials. Freely formable materials, such as concrete and plastics, have led, for example, to renewed interest into “blobby” forms in the 1950s and 1960s, as discussed in Chapter 1.
The contemporary emphasis on surface articulation is fundamentally related to the pos- sibilities and resistances offered by the intended material composition. New materials for architectural skins are offering the unprecedented thinness, dynamically-changing proper- ties, functionally-gradient composition, and an incredible repertoire of new surface effects. For example, the titanium sheets that cover the exterior of Gehry’s Guggenheim Museum in Bilbao have the thickness of only 0.38 mm. But it is not this thinness that is driving the increasing interest in new materials. The building skins are also acquiring a new complex- ity as new digital and mechanical networks become embedded into their composite layers. Structural skins with dynamic behavior are challenging the prevalent assumptions about the tectonics and the permanence of the material conditions.

Digital production 79
The old, familiar materials, such as brick, are today being used in novel ways, as shown by the sinuous masonry wall of the Craword Municipal Art Gallery (2000) in Cork, Ireland (figure 3.62), designed by Erick van Egeraat Architects, which emphasizes the new addi- tion while adhering to the local vernacular. Van Egeraat’s design is a contemporary version of the smooth, fluid forms of Eladio Dieste’s buildings constructed from bricks and mortar (figure 3.54). Beneath the plastered, curving exterior walls in one of the three office towers designed by Frank Gehry in Düsseldorf, Germany, is a framework construction of CNC cut steel rules with in-fill masonry (figure 3.63), a distant contemporary antecedent of Erich Mendelsohn’s Einsteinturm (1921, figure 1.4) in Potsdam, Germany, whose fluid shapes, conceived in concrete, were also realized in bricks and plaster.
3.62. Craword Municipal Art Gallery (2000), Cork, Ireland, architect Erick van Egeraat Architects.
3.63. Masonry walls in one of the Zollhof Towers (2000), Düsseldorf, Germany, architect Gehry Partners.

80 Architecture in the Digital Age
Conventional materials are being reconceptualized in new ways. For instance, the conven- tional steel rebar grid in reinforced concrete can be replaced with a non-corroding carbon fiber grid, producing concrete structures that are lighter and considerably stronger than steel reinforced concrete. Carbon fibers made from carbon nanotubes could even become the building material of the twenty-first century, replacing steel as the material of choice for the skeletal systems in buildings. Carbon atoms can create tiny spheres, which, with an appropriate catalyst, can form tiny, nano-scale edgeless tubes—“nanotubes” (figure 3.64)—that have very high strength and are much stronger than steel: a single nanotube (figure 3.65) can support more than a billion times its own weight! Once the bulk manu- facturing of nanotubes becomes a reality in a decade or so, we will probably start to see some incredibly thin, but exceptionally strong, beams and walls. Nanotubes could form “gossamer structures that open up spatial realms far beyond anything we could imagine,” according to Antoine Predock,15 who says that “blobs would seem heavy-handed by com- parison,” as “nanoscale structures would be like clouds.”
While new construction materials made of carbon nanotubes are still in the realm of the “not-yet” future, other commonly available materials, such as fiberglass, polymers and foams, offer several advantages over materials commonly used in current building prac- tice. They are lightweight, have high strength, and can be easily shaped into various forms. For example, the physical characteristics of fiberglass make it particularly suitable for the
3.64. Digital model of a double nanotube.
3.65. Microscopic image of a carbon nanotube.

Digital production 81
fabrication of complex forms. It is cast in liquid state, so it can conform to a mold of any shape and produce a surface of exceptional smoothness—a liquid, fluid materiality that produces liquid, fluid spatiality, as manifested in Kolatan and Mac Donald’s design for the Ost/Kuttner Apartments in New York (figure 2.26).
The “liquid” materials that have aroused particular interest among architects today are composites whose composition can be engineered precisely to meet specific performance criteria, and whose properties can vary across the section to achieve, for example, a dif- ferent structural capacity in the relationship to local stress conditions and surface require- ments. These layered materials, commonly used in automotive, aerospace, shipbuilding and other industries (figure 3.66), are experimented with for possible architectural appli- cations, as they offer the unprecedented capability to design material effects by digitally controlling the production of the material itself.
Composites are actually solid materials created, as their name suggests, by combining two or more different constituent material components, often with very different proper- ties. The result is a new material that offers a marked qualitative improvement in perfor- mance, with properties that are superior to those of the original components. A composite
3.66. Closeup of a bicycle frame made of a carbon fiber composite material.
material is produced by combining two principal components—the reinforcement and the matrix, to which other filler materials and additives could be added. The matrix is, typically, a metallic, ceramic or polymer material, into which multiple layers of reinforcement fibers, made from glass, carbon, polyethylene or some other material, are embedded. Lightweight fillers are often used to add volume to the composites with minimal weight gain, while various chemical additives are typically used to attain a desired color or to improve fire or thermal performance.

82 Architecture in the Digital Age
The actual components made from composite materials are usually formed over CNC- milled molds, as in boatbuilding, to produce boat hulls or large interior components, or in closed moulds by injecting the matrix material under pressure or by partial vacuum, as is done in the automotive industry for the production of smaller-scale components. In the building industry, composite panels are produced either through continuous lamination or by using the resin transfer molding.
Among composites, the polymer composite materials, or simply “plastics,” are being considered with renewed interest by architects, primarily because of their high formability, relatively low cost, minimum maintenance, and a relatively high strength-to-weight ratio. Plastics were used with great enthusiasm in the 1960s and 1970s because of their novelty as a material and their ability to take any shape, but the poor weathering capabilities, the shifting aesthetics of the late 1970s and early 1980s, and the ubiquity of plastic products, led to their second-class status later on.
It is the functionally gradient polymer composite materials that offer the promise of enclosures in which structure, glazing, and mechanical and electrical systems are synthesized into a single material entity. By optimizing material variables in composites for local per- formance criteria, entirely new material and tectonic possibilities open up in architecture. For example, transparency can be modulated in a single surface, and structural perfor- mance can be modulated by varying the quantity and pattern of reinforcement fibers, etc.16
Other possibilities are opened up by materials that change their properties dynamically in direct response to external and internal stimuli, such as light, heat and mechanical stresses. Kolatan and Mac Donald are exploring, in their speculative projects, materials such as “plastics that undergo molecular restructuring with stress,” “smart glass that responds to light and weather conditions,” “anti-bacterial woven-glass-fiber wall covering” and “pultruded fiberglass-reinforced polymer structural components.”
New skins begin to change not only their transparency and color, but also their shape in response to various environmental influences, as the Aegis Hyposurface project by Mark Goulthorpe shows. This project was developed initially as a competition entry for an interactive art piece to be exhibited in the Birmingham Hippodrome Theater foyer. The developed construct is a highly faceted metallic surface, which is actually a deformable, flexible rubber membrane covered with tens of thousands of triangular metal shingles (figure 3.67), and which can change its shape in response to electronic stimuli resulting from movement and changes in sound and light levels in its environment, or through parametrically-generated patterns. It is driven by an underlying mechanical apparatus that consists of several thousand pistons, which are controlled digitally, providing a real-time response. According to Goulthorpe, this project “marks the transition from autoplastic (determinate) to alloplas-tic (interactive, indeterminate) space;” it “utterly radicalize[s] architecture by announcing the possibility of dynamic form.”
Goulthorpe’s Aegis Hyposurface dynamic skin, a highly complex, electromechanical hybrid structure, whose sensors, pneumatic actuators, and computational and control sys- tems provide it with what could be called “intelligent” behavior, points to a material

Digital production 83
 3.67. Aegis Hyposurface (1999), architect Mark Goulthorpe/dECOi.
future in which it could become a fairly thin, single “intelligent” composite material with a “neural” system fully integrated into its layers.
“Intelligent,” “smart,” “adaptive” and other terms are used today to describe a higher form of composite materials that have sensing, actuation, control and intelligence capabili- ties. These composites have their own sensors, actuators, and computational and control firmware built into their layers. According to another definition, intelligent materials are those materials that possess adaptive capabilities to external stimuli through built-in “intel- ligence.” This “intelligence” of the material can be “programmed” through its composi- tion, its microstructure, or by conditioning to adapt in a certain manner to different levels of stimuli. The “intelligence” of the material can be limited to sensing or actuation only. For example, a sensory material is capable of determining particular material states or characteristics and sending an appropriate signal; an adaptive material is capable of alter- ing its properties, such as volume, opacity, color, resistance, etc. in response to external stimuli. An active material, however, contains both sensors and actuators, with a feedback loop between the two, and is capable of complex behavior—it can not only sense a new condition, but can also respond to it.
Some of the early “intelligent” materials, for example, were capable of sensing stress and temperature change through embedded sensors. The complexity, capacities, and utility of the “intelligent” materials, however, have increased dramatically over the past decade, with most of the research efforts concentrated on aerospace applications. Piezoelectric and optical sensors, for example, are embedded into composite material used as a skin in high- performance airplanes. These materially-integrated sensors continually measure stress and chemical changes within an airplane’s skin, detecting damage and transmitting an

84 Architecture in the Digital Age
appropriate signal. Similar sensory mechanisms, for example, are being embedded into “smart” concrete via tiny optical fibers, to monitor stresses and to detect potential dam- age. By producing materials in a digitally-controlled layer-by-layer fashion, as in additive fabrication, it is possible to embed various functional components, thus making them an integral part of a single, complex composite material.
The developing materials and technologies of the twenty-first century will radically redefine the relationship between architecture and its material reality. Future digital archi- tecture, in its conception and its realization, will respond dynamically to the internal logics and external influences of the environment. Designs are already “alive”—the buildings will soon be as well.
MASS-CUSTOMIZATION
The sparse geometries of the twentieth century Modernism were, in large part, driven by Fordian paradigms of industrial manufacturing, imbuing the building production with the logics of standardization, prefabrication and on-site installation. The rationalities of manu- facturing dictated geometric simplicity over complexity and the repetitive use of low-cost mass-produced components. But these rigidities of production are no longer necessary, as digitally-controlled machinery can fabricate unique, complexly-shaped components at a cost that is no longer prohibitively expensive. Variety, in other words, no longer compro- mises the efficiency and economy of production.
The ability to mass-produce one-off, highly differentiated building components with the same facility as standardized parts, introduced the notion of “mass-customization” into building design and production (it is just as easy and cost-effective for a CNC milling machine to produce 1,000 unique objects as to produce 1,000 identical ones). Mass-cus- tomization, the post-Fordian paradigm for the economy of the twenty-first century, was defined by Joseph Pine17 as the mass production of individually-customized goods and services, thus offering a tremendous increase in variety and customization without a cor- responding increase in costs. It was anticipated as a technological capability in 1970 by Alvin Toffler in Future Shock and was delineated, as well as named, in 1987 by Stan Davis in Future Perfect.18
3.68. Embryologic Houses (2000), architect Greg Lynn.

Digital production 85
Almost every segment of the economy, and industrial production in particular, has been affected by mass-customization, sometimes in very radical ways. Levi’s, for example, offers customized jeans, manufactured from body measurements taken by a scanner in one of its stores, at a cost slightly more than a standard pair. Motorola’s Paging Products Group lets its customers design their own pagers by choosing the desired frequency, tone, color, software, clips and other components (more than 29 million combinations are possible), and sells them at the same cost as their off-the-shelf predecessors. In Japan, Panasonic sells bicycles that are built to individual rider’s measurements, with customized color combina- tions and other options (with some 11 million possible variations), creating truly mass-pro- duced, built-to-fit, i.e. mass-customized machines.
Mass-customization is a particularly suitable production paradigm for the building industry, since buildings are mostly one-off, highly customized products. A “custom” house will become available to a broader segment of society. Eventually, the technolo- gies and “customization” methods that are developed in the consumer products industry will be applied to building products as well. In buildings, individual components could be mass-customized to allow for optimal variance in response to differing local conditions in buildings, such as uniquely shaped and sized structural components that address different structural loads in the most optimal way, variable window shapes and sizes that correspond to differences in orientation and available views. The digitally-driven production processes will introduce a different logic of seriality in architecture, one that is based on local varia- tion and differentiation in series. It is now possible to produce “series-manufactured, math- ematically coherent but differentiated objects, as well as elaborate, precise and relatively cheap one-off components,” according to Peter Zellner,19 who argues that in the process the “architecture is becoming like ‘firmware,’ the digital building of software space inscribed in the hardwares of construction.” That is precisely what Greg Lynn’s Embryologic Houses (figure 3.68) manifest: mass-customizable individual house designs produced by differen- tiation achieved through parametric variation in non-linear dynamic processes.
For Bernard Cache, “objects are no longer designed but calculated,”20 allowing the design of complex forms with surfaces of variable curvature and laying “the foundation for a nonstandard mode of production.” His objectiles (figure 3.69) are non-standard objects, mainly furniture and paneling, which are procedurally calculated in modeling software and are industrially produced with numerically-controlled machines. For Cache, it is the modification of parameters of design, often random, that allows the manufacture of dif- ferent shapes in the same series, thus making the mass-customization, i.e. the industrial production of unique objects, possible.
The implications of mass-customization for architecture and the building industry in general are profound. As Catherine Slessor observed, “the notion that uniqueness is now
 3.69. Objectiles, designer Bernard Cache.

86 Architecture in the Digital Age
economic and easy to achieve as repetition, challenges the simplifying assumptions of Modernism and suggests the potential of a new, post-industrial paradigm based on the enhanced, creative capabilities of electronics rather than mechanics.”21 In the Modernist aesthetic, the house was to be considered a manufactured item (“machine for living”). Mass production of the house would bring the best designs to a wide market and design would not no longer cater to the elite. That goal remains, albeit reinterpreted. The indus- trial production no longer means the mass production of a standard product to fit all pur- poses, i.e. one size fits all. The technologies and methods of mass-customization allow for the creation and production of unique or similar buildings and building components, differentiated through digitally-controlled variation.
NOTES
1 For more information about large-scale scanning, see Edward H. Goldberg, “Scan Your World with 3D Lasers” in Cadalyst, February 2001 (online at http://www.cadalyst.com/features/0201cyra/ index.htm).
2 William J.Mitchell. “Roll Over Euclid: How Frank Gehry Designs and Builds” in J.Fiona Ragheb (ed.), Frank Gehry, Architect. New York: Guggenheim Museum Publications, 2001, pp. 352– 363.
3 For more information about various fabrication technologies, see W. Mitchell and M.McCullough, “Prototyping” (Chapter 18) in Digital Design Media, 2nd edition. New York: Van Nostrand Rein- hold, 1995, pp. 417–440.
4 W.Mitchell and M.McCullough, “Prototyping” (Chapter 18) in Digital Design Media, 2nd edi- tion. New York: Van Nostrand Reinhold, 1995, pp. 417–440.
5 For more information about this project, see Thomas Rempen, Frank O. Gehry: der Neue Zollhof Düsseldorf. Essen, Germany: Bottrop, 1999; and Catherine Slessor, “Digitizing Dusseldorf” in Architecture, September 2000, pp. 118–125.
6 For more information about various rapid prototyping technologies, see Chee Kai Chua and Leong Kah Fai, Rapid Prototyping: Principles & Applications in Manufacturing. New York: Wiley, 1997; and Detlef Kochan. Solid Freeform Manufacturing: Advanced Rapid Prototyping. Amsterdam: Elsevier, 1993.
7 Behrokh Khoshnevis. “Innovative Rapid Prototyping” in Material Technology, vol. 13(2), 1998, pp. 53–56.
8 Annette LeCuyer. “Building Bilbao” in Architectural Review, December 1997, vol. 102, no. 1210, pp. 43–45.
9 Charles Linn. “Creating Sleek Metal Skins for Buildings” in Architectural Record, October 2000, pp. 173–178.
10 Annette LeCuyer. “Building Bilbao.” op cit.
11 Joseph Giovannini. “Building a Better Blob” in Architecture, September 2000, vol. 89, no. 9, pp.
126–128.
12 Ibid.
13 S.Stephens. “The Bilbao Effect” in Architectural Record, May 1999, pp. 168–173.
14 Annette LeCuyer. “Building Bilbao.” op cit.
15 See Erik Baard, “Unbreakable” in Architecture, June 2001, p. 52.

4
INFORMATION MASTER BUILDERS
BRANKO KOLAREVIC
The challenges of constructability left designers of new formal complexities with little choice but to become closely engaged in fabrication and construction, if they were to see their projects realized. Building contractors, used to the current “analog” norms of prac- tice and prevalent orthogonal geometries, were reluctant to take on projects they saw as apparently unbuildable or, at best, with unmanageable complexities. The “experimental architects had to find contractors and fabricators capable of digitally-driven production, who were often not in building but in shipbuilding. They had to provide, and often generate directly, the digital information needed to manufacture and construct the buildings. So, out of sheer necessity, the designers of the digitally-generated “blobby” architecture became closely involved in the digital making of buildings.
In the process, these architects discovered they have the digital information that could be used in fabrication and construction to directly drive the computer-controlled machin- ery, making the time-consuming and error-prone production of drawings unnecessary. In addition, the introduction and integration of digital fabrication into the design of buildings enabled architects to almost instantaneously produce scale models of their designs using processes and techniques identical to those used in the industry. Thus, a valuable feedback mechanism between conception and production was established.
This newfound ability to generate construction information directly from design infor- mation, and not the complex curving forms, is what defines the most profound aspect of much of the contemporary architecture. The close relationship that once existed between architecture and construction (what was once the very nature of architectural practice) could potentially reemerge as an unintended but fortunate outcome of the new digital processes of production. In the future, being an architect will also mean being a builder, not literally, of course, but by digitally generating the information to manufacture and construct build- ings in ways that render present inefficient hierarchies of intermediation unnecessary.
The new processes of design and production, born out of the pragmatic ramifications of new formal complexities, are providing unprecedented opportunities for architects to regain the authority they once had over the building process, not only in design, but also in construction. The new relationships between the design and the built work place more control, and, therefore, more responsibility and more power into the hands of architects.
By integrating the design, analysis, manufacture and assembly of buildings around digi- tal technologies, architects, engineers and builders have an opportunity to fundamentally redefine the relationships between conception and production. By reinventing the role of a “master builder,” the currently separate disciplines of architecture, engineering and con- struction can be integrated into a relatively seamless digital collaborative enterprise, thus

Information master builders 89 bridging “the gap between designing and producing that opened up when designers began
to make drawings,” as observed by Mitchell and McCullough.1
HISTORY OF DISASSOCIATION
For centuries, being an architect also meant being a builder. Architects were not only the masters of spatial effects, but were also closely involved in the construction of buildings. The knowledge of building techniques was implicit in architectural production; inventing the building’s form implied inventing its means of construction, and vice versa. The design information was the construction information—one implied the other.
The master builders, from the Greek tekton (builder), to the master masons of the Mid- dle Ages were in charge of all aspects of buildings, from their form to the production techniques used in their construction. They had the central, most powerful position in the production of buildings, stemming from their mastery of the material (stone in most cases) and its means of production. As the palette of materials broadened and the construction techniques became more elaborate, the medieval master masons evolved into master build- ers (or architects) who would integrate increasingly multiplying trades into an increasingly more complex production process.
The tradition of master builders, however, did not survive the cultural, societal and eco- nomic shifts of the Renaissance. Leon Battista Alberti wrote that architecture was separate from construction, differentiating architects and artists from master builders and craftsmen by their superior intellectual training. The theory was to provide the essence of architec- ture, and not the practical knowledge of construction.
Paradoxically, the history of architecture’s disassociation from building started in the late Renaissance with one of its most celebrated inventions—the use of perspective repre- sentation and orthographic drawings as a medium of communicating the information about buildings. The medieval master builder (architect) used very few models and drawings to test or communicate ideas, and relied instead on direct verbal communication with crafts- men, which, in turn, required continuous presence on site, but provided for a seamless exchange of information at all phases of building. With Alberti’s elevation of architects over master builders came the need to externalize information (so it could be communi- cated to tradesmen) and the introduction of orthographic abstractions, such as plan, section and elevation, into the currency of building. Architects no longer had to be present on site to supervise the construction of the buildings they designed.
The rifts between architecture and construction started to widen dramatically in the mid- nineteenth century when “drawings” of the earlier period became “contract documents.” Other critical developments occurred, such as the appearance of a general contractor and a professional engineer (first in England), which were particularly significant for the devel- opment of architectural practice as we know it today. The relationships between architects and other parties in the building process became defined contractually, with the aim of clearly articulating the responsibilities and potential liabilities. The consequences were profound. The relationship between an architect (as a designer of a building) and a general contractor (as an executor of the design) became solely financial, leading to what was to

90 Architecture in the Digital Age
become, and remain to this day, an adversarial, highly legalistic and rigidly codified pro- cess. It is the biggest obstacle to change today.
The late-nineteenth century New York firm McKim, Mead and White is often cited as another example of the power architects once had over the building process. As described by Howard Davis,2 this architectural firm, in its quest for total control over the construction of each of their buildings, produced not only hundreds of drawings, but also had a final say over every detail, the quality of materials and workmanship, and over every payment to con- tractors and subcontractors. But this high degree of control was not without consequences. As architects placed more and more layers beneath themselves, the distance between them and the construction site increased. As Davis observes, “As the system evolved further, the role of the general contractor grew at the same time as the architect’s connection to craft- speople lessened.”3 Although architects were at the apex of hierarchical control structure, increasingly the desired outcome had to be explicitly and precisely described in various contract documents. The architect’s role on the construction site, instead of shaping the building (as master builders once did), became the contractual administration, i.e. the veri- fication of the contractor’s compliance with the given contractual construction documents. The design was split from the construction, conceptually and legally. Architects detached themselves fully from the act of building, unintentionally giving up the power they once had, pushing the design to a sideline, and setting the profession on a path of increasing irrelevance in the twentieth century.
The twentieth century brought increasing complexity to building design and construc- tion, as numerous new materials, technologies and processes were invented. With increased complexity came increased specialization, and the emergence of various design and engi- neering consultants for different building systems, code compliance, etc. At the same time, the amount of time allotted for design and construction was shrinking. As the complexity of building increased and the design “time” decreased, the architects sought the need to limit their liability exposure. While the legal definition of their role was becoming progres- sively more defined, architects were, at the same time, increasingly losing control and the decision-making power over the building process, thereby formally dissolving the author- ity they once had and knowingly disassociating themselves from the rest of the building industry.
In the United States today, architects are prohibited from taking part in construction by the codes of practice established by the professional association, the American Institute of Architects (AIA). The standard contracts in use by the AIA state explicitly that “the archi- tect will not have control over or charge of and will not be responsible for construction means, methods, techniques, sequences, or procedures.”4 This aversion to risk has, unsur- prisingly, led to the further marginalization of architectural design, further contraction in services offered by the design firms, and further reduction in fees.
The outcome of this progressive disassociation of architecture from the rest of the build- ing industry is a profession unsure of its role in contemporary society and its economy, and a profession unable to respond to the challenges and opportunities of the Information Age. Only by taking the lead in the inevitable digitally-driven restructuring of the building industry will architects avoid becoming irrelevant.

Information master builders 91 THE DIGITAL CONTINUUM
It is debatable whether the drawings emerged in the building industry because of the need to separate design and construction or whether their introduction produced the present separation. The lasting legacy is the legal framework within which building industry pro- fessionals operate today, requiring drawings, often tens of thousands of them, for a project of medium size and complexity.
Only the present divisions of responsibility make this production of drawings necessary. In other industries, such as shipbuilding, the designer and the builder are often one legal entity, so there is little or no need to produce drawings, i.e. to externalize design informa- tion. Many shipyards and boatyards have eliminated drawings by working directly with a comprehensive three-dimensional digital model from design to construction. The digital geometric data extracted from the model are used to drive the automated fabrication and assembly equipment.
Fortunately, the digital revolution that radically restructured the shipbuilding and other industries did not go unnoticed in architecture. Some architects were quick to exploit the design and construction opportunities that were opened up by the newfound ability to digi- tally generate and supply the manufacturing information to fabricators and contractors, and, in turn, their ability to reciprocate by providing accurate material and cost estimates. In these newly discovered mutually-beneficial processes of direct information exchange, the digital design information became the construction information, and vice versa, with- out the intermediate time-consuming and error-prone steps of drawing production. These digital processes, pioneered by Frank Gehry’s office, represent a radical departure from the normative practices—they eliminate, rather than automate, the production of various construction documents as paper drawings. The digital data are passed on directly, i.e. in paperless fashion, to fabricators for cost estimation and fabrication.
The ability to digitally generate and analyze the design information, and then use it directly to manufacture and construct buildings, fundamentally redefines the relationships between conception and production—it provides for an informational continuum from design to construction. New synergies in architecture, engineering and construction start to emerge because of the use of digital technologies across the boundaries of various pro- fessions. As communication among various parties increasingly involves the direct digital exchange of information, the legacy of the twentieth century in the form of drawing sets, shop drawings and specifications, will be inevitably relegated to the dustbin of history. The need to externalize representations of design, i.e. produce drawings, will lessen as a direct consequence of the new digital possibilities for producing and processing information.
As production of the drawings declines, i.e. as digital data are increasingly passed directly from an architect to an engineer or a fabricator, and vice versa, so will the building design and construction processes become more efficient. By some estimates, there is a potential for building construction to become 28–40% more efficient through better (digi- tal) information and coordination.5 But for that process to begin, the legal framework of the building industry, in which the drawings establish the grounds of liability, would have to change. In other words, the nineteenth century building practices would have to change for architects to work directly with fabricators, i.e. subcontractors. This “disintermedia- tion”6 should bring new efficiencies. According to James Cramer, Chairman and CEO of

92 Architecture in the Digital Age
Greenway Consulting, architects will find themselves “moving from linear to non-linear changes—from information that is shared by teams, rather than individuals, and communi- cation that is continuous, rather than formal and fragmented.”7
In this scenario, the digital model becomes the single source of design and production information that is generated, controlled and managed by the designer. It encodes all the information needed to manufacture and construct the building. Layers of information are added, abstracted and extracted as needed throughout the design and construction, as archi- tects, engineers, contractors and fabricators work in a collaborative fashion using a single digital model from the earliest stages of design.
Such a model of production requires that all tools for design, analysis, simulation, fab- rication and construction be integrated into a single, cohesive digital environment that can provide information about any qualitative or quantitative aspect of building under design or construction. The challenge is (and has been for more than three decades of computer- aided design) how to develop an information model that facilitates all stages of building, from conceptual design to construction (and beyond, for facilities management), and pro- vides for a seamless digital collaborative environment among all parties in the building process.
For Gehry’s office, a digital model created in CATIA—the design and manufacturing software used mainly in the aerospace industry—is the single source of design and con- struction information. In a remarkable departure from the current norms of practice, the three-dimensional digital model is actually a key part of the contract documents, from which all dimensional information is to be extracted during the fabrication and construc- tion of the building. In other words, the digital model takes precedence over any other construction document, legally and in practice, on the construction site. This is a radi- cal, revolutionary change in building practice, for which Gehry’s office will probably be remembered in future history books (and not only for the sinuous, curving geometries of the Guggenheim Museum in Bilbao, Spain).
The single, unified digital model, as envisioned by Jim Glymph, one of Gehry’s part- ners, places the architect in the role of a “coordinator of information”8 between the various participants in the design and construction of a building. The principal idea is to unify, i.e. to bring together in a single digital information environment, the hundreds of different par- ties involved in a typical building production, with the aim of overcoming the inefficien- cies, resource-wise and information-wise, that result from the conventional divisions of responsibility and modes of production in the various professions.
Gehry’s office first experimented with the “paperless” process of digital production in the late 1980s in the design and construction of the large fish-shaped pavilion at the entrance of a retail complex on Barcelona’s waterfront (1992, figure 3.1). It was a water- shed project for the office. As was the case with all of Gehry’s projects later on, a physical design model was first generated and then translated into a corresponding digital surface model. The digital model was further refined; the wireframe model was extracted and used by structural engineers to develop the supporting structural frame. A physical scale model was machined from the digital version for comparison with the initial conceptual model. The digital model was then used in the full-scale construction to directly control the pro- duction and assembly of the components. For the first time, the construction drawings were not needed to erect the building. This process of project development and production, with

Information master builders 93
some variations, was used by Gehry’s office on a number of projects. Particularly notable among recent projects are the Experience Music Project (2000) in Seattle (figures 3.9a-b), and the Walt Disney Concert Hall (2003) in Los Angeles (figure 8.1), whose design and construction represents the most complete use of digital technology by Gehry’s office so far.
According to Gehry, particularly appealing is the newfound ability “to get closer to the craft”9 by engaging the digital technology directly in the production and thus eliminating the many layers that exist between the architect and the act of building. To Gehry, that means one thing—“it’s the old image of the architect as master builder,” who now has control over the building process from beginning to end. Thus, the basic idea of the Bauhaus (of the unity of the craftsman and the artist) from the early twentieth century is reactualized at the beginning of the twenty-first century.
CHALLENGES
In the new digitally-driven processes of production, design and construction are no longer separate realms but are, instead, fluidly amalgamated. Builders and fabricators become involved in the earliest phases of design, and architects actively participate in all phases of construction. The fission of the past is giving way to the digital fusion.
This model of a digitally-facilitated collaborative continuum from design to construction, while opening up unprecedented opportunities for the building industry, faces a number of difficult, multifaceted challenges, which must be overcome for this new digital continuum to become a reality. The principal obstacles stem from the long-established social and legal practices in the industry. Its highly fragmented and differentiated structure, which facilitates a clear definition of the responsibilities, does stand in the way of new collaborative synergies emerging in the industry.
The sharing of digital data among various parties in the building process is, in fact, discouraged by the current legal codes of practice. Under the current definitions of professional liability, if an architect transmits a digital model or a drawing to a contractor or a fabricator, he or she becomes liable for any work resulting from the given digital data. The consequence is that each participating party in design and construction creates its digital data from scratch, i.e. from paper documents reproduced from the previously digitally-generated information. Needless to say, this process is not only highly redundant and utterly inefficient, but it al- so compounds any errors that could occur in interpreting the information exchanged on paper.
While uniting all the participants through a single modeling system, as discussed earlier, does hold a promise of a remedy for the present redundancies and inefficiencies, it makes the responsibilities of different parties far less distinct than is presently the case. If the building industry were to adopt this new modus operandi of shared responsibilities, it needs to clearly assess the legal repercussions and embark on a fundamental redefinition of relationships among various parties in the building industry, with the help of legal and insurance experts. A radical restructuring of the industry, while technologically possible today, is an enormously difficult task because of the tremendous social and cultural inertia of the firmly entrenched traditions, developed slowly over several centuries.

The transition then is likely to be evolutionary rather than revolutionary. Gehry’s office, for example, relies on a “hybrid” system in which an owner-contracted consulting firm (called C-cubed, and led by Rick Smith) provides digital modeling services in CATIA to all members of the design and construction team, effectively coordinating the production of the shared digital model. Each team member extracts and adds information to the shared model as mandated by their expertise without crossing the traditional lines of responsibility and thus staying within the limits of liability established by the legal and insurance rules. Had Gehry’s office assumed the responsibility for the development and data coordination of the digital model, they could have been liable legally as a professional architectural firm for the information provided by other members of the team.
While this solution protects the architect and creates an elegant legal “umbrella” for the rest of the design and construction team under the existing rules, it places significant responsibility on the owner-contracted consulting firm as a “data manager.” This is an emerging role that needs a full and clear definition as challenges of accurate and integrative production of information become more and more demanding. It is this role—the information master builder—that represents the greatest opportunity for architects to return to their master-builder roots. The architectural profession will seal its fate if it abandons the overall process and information integration and management to construction and engineer- ing firms, some of which have already realized that the emerging dynamic, geographically distributed, digital networks of design and production expertise are the future mode of operation for the building industry.
With greater responsibility comes increased liability, i.e. a greater assumption of risk, but also greater rewards. According to Jim Glymph, “both money and time can be eliminated from the construction process by shifting the design responsibility forward.”10 Glymph offers, as an example, the cost of producing the shop drawings, which far exceeds the architectural and engineering fees for a typical large-scale project. But if architects were to provide the information for the benefit of other members of the design and construction team, they ought to be compensated for that new role. The restructuring of the industry therefore requires not only professional and organizational adjustments, but also a rethink- ing of how various members of the team are compensated.
In the Stata Center for Computer, Information, and Intelligence Sciences (2003) at MIT, Gehry’s office is breaking new ground by sharing the overall responsibility for the project with other members of the building team. The concept of shared liability is a remarkable departure from the current distributed liability of building practice. It is, perhaps, the most difficult challenge to overcome, as it represents a complete reversal of the present position by architectural professional organizations and insurance companies of minimizing the liability of architects in the building process. If they are to remain relevant as a profession, architects will have to learn to share responsibility with other members of the building team, as they once did.
Some architects have responded to the opportunities and challenges that come with shared responsibility by teaming up with contractors to create design-build  rms, which serve as both architect and contractor to the owner, thus representing a single legal entity and a single point of responsibility. This change in the structure of building practices, and the resultant redefined legal framework that provides for shared decision-making, is one possible logical remedy for the present inefficiencies of a highly fragmented building

Information master builders 95
industry. By some estimates, one-quarter of all construction projects in England and one- tenth in the United States are now done as design-build.11
Design-build, however, is only one way of actualizing the emerging professional syner- gies of digitally-driven modes of production. A more interesting possibility is the structur- ing of building teams as dynamic, geographically-distributed digital networks of design and production expertise, which change fluidly as the circumstances of the project or prac- tice require. Architects will increasingly find themselves working in an environment of multidirectional digitally-mediated exchange of knowledge among various members of design and construction teams. In the emerging fluid, heterogeneous processes of produc- tion, the digital data, software and various manufacturing devices will be used in different ways by different members of the building team, who will often operate in different places and in different time zones.
As architects shift their attention from drawing production to digital information author- ing, the software industry has a very important role to play in the transition to emerging digital modes of practice. Instead of adopting a conservative stance, which calls for provid- ing technologies based on prevalent modes of practice, it has to actively engage in devel- oping the tools that support new modes of production. In partnership with the building industry, it must overcome existing social and cultural barriers to technological innovation and must aggressively promote a new culture of use based on a single building model.
Educational institutions are the ones who have the power (and, hopefully, the foresight) to prepare future generations of professionals for the emerging practices of the digital age. We need to start training architects to be master builders again, to understand and re-engage the processes of building through digital technologies.
THE INEVITABLE
As architects find themselves increasingly working across other disciplines, such as mate- rial science and computer-aided manufacturing, the historic relationships between archi- tecture and its means of production are increasingly being challenged by the emerging digitally-driven processes of design, fabrication and construction. The amalgamation of what were, until recently, separate enterprises has already transformed other industries, such as aerospace, automotive and shipbuilding, but there has yet to be a similarly sig- nificant and industry-wide impact in the world of building design and construction. That change, however, has already started, and is inevitable and unavoidable. The obstacles are numerous but the rewards are compelling if architects can manage to liberate the profes- sion from the anachronistic practices of the twentieth century.
If nothing else, eventually the sheer number of digitally-produced projects will bring about a new way of thinking about architecture and its proper place within the building industry. Many of the strategies and techniques of production, which are pioneered today by Frank Gehry and his numerous less-known but more adventurous, younger colleagues, will be commonplace tomorrow, just as the material and technological innovations of the nineteenth century eventually became mainstream in the twentieth century.
